{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:06.334432Z",
     "start_time": "2018-07-06T00:13:06.302931Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:06.838000Z",
     "start_time": "2018-07-06T00:13:06.337725Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:06.856150Z",
     "start_time": "2018-07-06T00:13:06.840322Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:07.019447Z",
     "start_time": "2018-07-06T00:13:06.858432Z"
    }
   },
   "outputs": [],
   "source": [
    "from data.frecency import sample, frecency_points\n",
    "from data.frecency import sample_suggestions_normal as sample_suggestions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression\n",
    "\n",
    "This section is mostly to check that's it possible to fit a linear model perfectly to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:07.449049Z",
     "start_time": "2018-07-06T00:13:07.021372Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit a model, we sample a lot of these scores and also add noise on top to make the problem more similar to the real application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:08.724726Z",
     "start_time": "2018-07-06T00:13:08.400635Z"
    }
   },
   "outputs": [],
   "source": [
    "n = int(1e6)\n",
    "noise = np.random.normal(0, 2, size=(n))\n",
    "X, y = sample(n)\n",
    "y += noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:10.123284Z",
     "start_time": "2018-07-06T00:13:09.291773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=False, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(fit_intercept=False)\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting coefficients are extremely close to the actual frecency weights. How close they are depends on how much noise we add to the data matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:10.722421Z",
     "start_time": "2018-07-06T00:13:10.698627Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(120.00159750999515, 120.0),\n",
       " (35.994674183889856, 36.0),\n",
       " (97.99060385491362, 98.0),\n",
       " (14.011544426351845, 14.0),\n",
       " (20.00909549464527, 20.0),\n",
       " (100.00919657578298, 100.0),\n",
       " (140.00754060124282, 140.0),\n",
       " (69.99600472596933, 70.0),\n",
       " (199.98257062705986, 200.0),\n",
       " (41.993561491778806, 42.0),\n",
       " (60.0031611350459, 60.0),\n",
       " (139.99371551616719, 140.0),\n",
       " (11.996226935356527, 12.0),\n",
       " (60.00358900094553, 60.0),\n",
       " (83.9972314373345, 84.0)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(model.coef_, frecency_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:11.239433Z",
     "start_time": "2018-07-06T00:13:11.216532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00159751, -0.00532582, -0.00939615,  0.01154443,  0.00909549,\n",
       "        0.00919658,  0.0075406 , -0.00399527, -0.01742937, -0.00643851,\n",
       "        0.00316114, -0.00628448, -0.00377306,  0.003589  , -0.00276856])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_ - frecency_points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking and SVM loss\n",
    "\n",
    "Now, we make the problem slightly more difficult: Instead of just learning the frecency function from data, we try to learn it from user interactions. The training data now consists of a variable number of history suggestions and their respective features. The label corresponds to the suggestion that the user clicked on. We still assume that the user clicks on the item with the highest frecency score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent generally works better when the data is centered around the origin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:13.055710Z",
     "start_time": "2018-07-06T00:13:13.036010Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:20.508354Z",
     "start_time": "2018-07-06T00:13:13.429733Z"
    }
   },
   "outputs": [],
   "source": [
    "X = normalize(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:20.572382Z",
     "start_time": "2018-07-06T00:13:20.510420Z"
    }
   },
   "outputs": [],
   "source": [
    "from optimizers import GradientDescent, AdaptiveGradientDescent, DecayedGradientDescent, RProp, Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hinge Loss (SVM loss)\n",
    "\n",
    "To supervise training, we keep logging the loss:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:20.680592Z",
     "start_time": "2018-07-06T00:13:20.574513Z"
    }
   },
   "outputs": [],
   "source": [
    "def svm_loss(preds, ys, delta=0):\n",
    "    correct = ys.argmax()\n",
    "    score_correct = preds[correct]\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for i, pred in enumerate(preds):\n",
    "        loss += max(0, pred + delta - score_correct)            \n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, we want to supervise the learning process and save the best models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:20.790356Z",
     "start_time": "2018-07-06T00:13:20.683111Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "accuracy needs to be measured carefully here: In our simulation, we assume that the current frecency is the perfect ranking function. But because items sometimes get the same frecency scores, there can be more than one correct answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:20.902274Z",
     "start_time": "2018-07-06T00:13:20.792321Z"
    }
   },
   "outputs": [],
   "source": [
    "def rank_accuracy(y, preds):\n",
    "    correct = 0.\n",
    "    \n",
    "    for yi, pi in zip(y, preds):\n",
    "        if yi[pi.argmax()] == yi.max():\n",
    "            correct += 1\n",
    "            \n",
    "    return correct / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `SVMRanking` class is the main mechanism for fitting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:13:21.036099Z",
     "start_time": "2018-07-06T00:13:20.904264Z"
    }
   },
   "outputs": [],
   "source": [
    "class SVMRanking:\n",
    "    def __init__(self, delta):\n",
    "        self.delta = delta\n",
    "        \n",
    "    def fit(self, data_generator, optimizer, num_iterations=10, callbacks=[]):\n",
    "        X, y = data_generator(2)\n",
    "        num_features = X[0].shape[1]\n",
    "        self.W = frecency_points + (np.random.random(size=(num_features)) - 0.5) * 100\n",
    "        \n",
    "        for j in range(num_iterations):\n",
    "            X, y = data_generator(4000)\n",
    "            \n",
    "            preds = self.predict(X)\n",
    "            gradient = np.zeros(num_features)\n",
    "\n",
    "            for xi, pi, yi in zip(X, preds, y):\n",
    "                correct = yi.argmax()\n",
    "                score_correct = pi[correct]\n",
    "\n",
    "                for i, predicted_score in enumerate(pi):\n",
    "                    gradient -= xi[i] * max(0, predicted_score + self.delta - score_correct)\n",
    "            \n",
    "            gradient /= len(X)\n",
    "            \n",
    "            loss = np.mean([svm_loss(pi, yi) for pi, yi in zip(self.predict(X), y)])\n",
    "            accuracy = rank_accuracy(y, model.predict(X))\n",
    "            \n",
    "            print(\"[%d/%d] training: %.5f loss, %.3f accuracy\" % (j + 1, num_iterations, loss, accuracy))\n",
    "            \n",
    "            for callback in callbacks:\n",
    "                callback(self)\n",
    "            \n",
    "            self.W += optimizer(gradient)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        \n",
    "        for x in X:\n",
    "            scores = x.dot(self.W)\n",
    "            preds.append(scores)\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:14:26.871877Z",
     "start_time": "2018-07-06T00:13:21.038362Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training: 3.80225 loss, 0.787 accuracy\n",
      "[ModelCheckpoint] New best model with 0.79670 validation accuracy\n",
      "[2/48] training: 1.60038 loss, 0.944 accuracy\n",
      "[ModelCheckpoint] New best model with 0.94620 validation accuracy\n",
      "[3/48] training: 0.77972 loss, 0.963 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96370 validation accuracy\n",
      "[4/48] training: 0.63540 loss, 0.964 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96460 validation accuracy\n",
      "[5/48] training: 0.35693 loss, 0.968 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[6/48] training: 0.56707 loss, 0.967 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[7/48] training: 0.39944 loss, 0.965 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96570 validation accuracy\n",
      "[8/48] training: 0.33584 loss, 0.961 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96870 validation accuracy\n",
      "[9/48] training: 0.40017 loss, 0.963 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[10/48] training: 0.25135 loss, 0.967 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[11/48] training: 0.14411 loss, 0.970 accuracy\n",
      "validation: 0.962 accuracy\n",
      "[12/48] training: 0.14909 loss, 0.962 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[13/48] training: 0.15105 loss, 0.965 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[14/48] training: 0.10008 loss, 0.969 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[15/48] training: 0.12976 loss, 0.965 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[16/48] training: 0.11980 loss, 0.970 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[17/48] training: 0.09692 loss, 0.964 accuracy\n",
      "validation: 0.967 accuracy\n",
      "[18/48] training: 0.08039 loss, 0.966 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[19/48] training: 0.09652 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[20/48] training: 0.06384 loss, 0.965 accuracy\n",
      "validation: 0.968 accuracy\n",
      "[21/48] training: 0.05389 loss, 0.962 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[22/48] training: 0.06603 loss, 0.964 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[23/48] training: 0.04978 loss, 0.965 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[24/48] training: 0.05702 loss, 0.961 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[25/48] training: 0.03534 loss, 0.962 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[26/48] training: 0.05088 loss, 0.965 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[27/48] training: 0.04353 loss, 0.960 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[28/48] training: 0.02919 loss, 0.965 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[29/48] training: 0.04597 loss, 0.961 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[30/48] training: 0.04546 loss, 0.965 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[31/48] training: 0.05533 loss, 0.964 accuracy\n",
      "validation: 0.968 accuracy\n",
      "[32/48] training: 0.03115 loss, 0.962 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[33/48] training: 0.02815 loss, 0.962 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[34/48] training: 0.01073 loss, 0.969 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[35/48] training: 0.00830 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[36/48] training: 0.03234 loss, 0.966 accuracy\n",
      "validation: 0.962 accuracy\n",
      "[37/48] training: 0.02458 loss, 0.966 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[38/48] training: 0.02474 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[39/48] training: 0.01768 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[40/48] training: 0.01838 loss, 0.966 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[41/48] training: 0.03372 loss, 0.962 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[42/48] training: 0.01719 loss, 0.963 accuracy\n",
      "validation: 0.967 accuracy\n",
      "[43/48] training: 0.00932 loss, 0.964 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[44/48] training: 0.01877 loss, 0.963 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[45/48] training: 0.01093 loss, 0.965 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[46/48] training: 0.00770 loss, 0.963 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[47/48] training: 0.01093 loss, 0.964 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[48/48] training: 0.02531 loss, 0.963 accuracy\n",
      "validation: 0.967 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "model = SVMRanking(delta=0.)\n",
    "model.fit(data_generator=sample_suggestions,\n",
    "          optimizer=GradientDescent(30.),\n",
    "          num_iterations=48,\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:17:03.147327Z",
     "start_time": "2018-07-06T00:15:57.407354Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training: 3.80225 loss, 0.787 accuracy\n",
      "[ModelCheckpoint] New best model with 0.79670 validation accuracy\n",
      "[2/48] training: 4.16381 loss, 0.802 accuracy\n",
      "[ModelCheckpoint] New best model with 0.80270 validation accuracy\n",
      "[3/48] training: 4.18797 loss, 0.793 accuracy\n",
      "[ModelCheckpoint] New best model with 0.80420 validation accuracy\n",
      "[4/48] training: 3.97512 loss, 0.803 accuracy\n",
      "validation: 0.803 accuracy\n",
      "[5/48] training: 3.50770 loss, 0.802 accuracy\n",
      "validation: 0.794 accuracy\n",
      "[6/48] training: 4.08533 loss, 0.794 accuracy\n",
      "validation: 0.803 accuracy\n",
      "[7/48] training: 3.82384 loss, 0.796 accuracy\n",
      "validation: 0.801 accuracy\n",
      "[8/48] training: 3.76828 loss, 0.796 accuracy\n",
      "validation: 0.804 accuracy\n",
      "[9/48] training: 3.70492 loss, 0.804 accuracy\n",
      "validation: 0.796 accuracy\n",
      "[10/48] training: 3.74066 loss, 0.795 accuracy\n",
      "validation: 0.793 accuracy\n",
      "[11/48] training: 3.10902 loss, 0.804 accuracy\n",
      "validation: 0.802 accuracy\n",
      "[12/48] training: 3.05052 loss, 0.796 accuracy\n",
      "validation: 0.799 accuracy\n",
      "[13/48] training: 3.20198 loss, 0.798 accuracy\n",
      "validation: 0.794 accuracy\n",
      "[14/48] training: 2.48176 loss, 0.800 accuracy\n",
      "validation: 0.803 accuracy\n",
      "[15/48] training: 2.65770 loss, 0.804 accuracy\n",
      "validation: 0.801 accuracy\n",
      "[16/48] training: 2.49406 loss, 0.802 accuracy\n",
      "validation: 0.801 accuracy\n",
      "[17/48] training: 2.53305 loss, 0.801 accuracy\n",
      "validation: 0.796 accuracy\n",
      "[18/48] training: 1.80028 loss, 0.907 accuracy\n",
      "[ModelCheckpoint] New best model with 0.90240 validation accuracy\n",
      "[19/48] training: 2.04018 loss, 0.901 accuracy\n",
      "[ModelCheckpoint] New best model with 0.90310 validation accuracy\n",
      "[20/48] training: 1.96591 loss, 0.897 accuracy\n",
      "validation: 0.901 accuracy\n",
      "[21/48] training: 1.70630 loss, 0.900 accuracy\n",
      "validation: 0.901 accuracy\n",
      "[22/48] training: 1.64377 loss, 0.896 accuracy\n",
      "validation: 0.901 accuracy\n",
      "[23/48] training: 1.48028 loss, 0.900 accuracy\n",
      "validation: 0.901 accuracy\n",
      "[24/48] training: 1.27568 loss, 0.898 accuracy\n",
      "validation: 0.902 accuracy\n",
      "[25/48] training: 1.06033 loss, 0.890 accuracy\n",
      "validation: 0.902 accuracy\n",
      "[26/48] training: 0.90777 loss, 0.900 accuracy\n",
      "validation: 0.902 accuracy\n",
      "[27/48] training: 0.80583 loss, 0.910 accuracy\n",
      "[ModelCheckpoint] New best model with 0.90980 validation accuracy\n",
      "[28/48] training: 0.69074 loss, 0.917 accuracy\n",
      "validation: 0.909 accuracy\n",
      "[29/48] training: 0.69501 loss, 0.913 accuracy\n",
      "[ModelCheckpoint] New best model with 0.91030 validation accuracy\n",
      "[30/48] training: 0.48011 loss, 0.971 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97190 validation accuracy\n",
      "[31/48] training: 0.53956 loss, 0.971 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97210 validation accuracy\n",
      "[32/48] training: 0.27056 loss, 0.971 accuracy\n",
      "validation: 0.971 accuracy\n",
      "[33/48] training: 0.32599 loss, 0.971 accuracy\n",
      "validation: 0.970 accuracy\n",
      "[34/48] training: 0.18920 loss, 0.974 accuracy\n",
      "validation: 0.967 accuracy\n",
      "[35/48] training: 0.14999 loss, 0.989 accuracy\n",
      "[ModelCheckpoint] New best model with 0.99010 validation accuracy\n",
      "[36/48] training: 0.24723 loss, 0.990 accuracy\n",
      "validation: 0.989 accuracy\n",
      "[37/48] training: 0.20590 loss, 0.987 accuracy\n",
      "validation: 0.988 accuracy\n",
      "[38/48] training: 0.17077 loss, 0.990 accuracy\n",
      "validation: 0.989 accuracy\n",
      "[39/48] training: 0.10608 loss, 0.992 accuracy\n",
      "validation: 0.989 accuracy\n",
      "[40/48] training: 0.11117 loss, 0.988 accuracy\n",
      "[ModelCheckpoint] New best model with 0.99070 validation accuracy\n",
      "[41/48] training: 0.14862 loss, 0.984 accuracy\n",
      "validation: 0.988 accuracy\n",
      "[42/48] training: 0.07952 loss, 0.986 accuracy\n",
      "validation: 0.990 accuracy\n",
      "[43/48] training: 0.04846 loss, 0.995 accuracy\n",
      "[ModelCheckpoint] New best model with 0.99540 validation accuracy\n",
      "[44/48] training: 0.05544 loss, 0.989 accuracy\n",
      "validation: 0.991 accuracy\n",
      "[45/48] training: 0.04586 loss, 0.989 accuracy\n",
      "validation: 0.989 accuracy\n",
      "[46/48] training: 0.03665 loss, 0.986 accuracy\n",
      "validation: 0.990 accuracy\n",
      "[47/48] training: 0.03562 loss, 0.985 accuracy\n",
      "validation: 0.989 accuracy\n",
      "[48/48] training: 0.06579 loss, 0.987 accuracy\n",
      "validation: 0.990 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "opt = AdaptiveGradientDescent(0.1, len(frecency_points))\n",
    "model = SVMRanking(delta=0.)\n",
    "model.fit(data_generator=sample_suggestions,\n",
    "          optimizer=opt,\n",
    "          num_iterations=48,\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy,  sample_suggestions)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After fitting, we can compare the learned weights with the true frecency scores. Note that the values themselves are very different now but that the ordering is nearly the same as in the real algorithm. This shows that we are ranking very similarly to the real algorithm but that the optimization process did not fully reach the global optimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:17:03.195582Z",
     "start_time": "2018-07-06T00:17:03.149428Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.0, -25.894926149162654),\n",
       " (14.0, -11.4372848210452),\n",
       " (20.0, -28.121019956364485),\n",
       " (36.0, 16.02788591203444),\n",
       " (42.0, 17.034268043118946),\n",
       " (60.0, 16.89757031759994),\n",
       " (60.0, 16.022547162926983),\n",
       " (70.0, 81.69339968747569),\n",
       " (84.0, 93.61502353018228),\n",
       " (98.0, 93.61503322165485),\n",
       " (100.0, 96.45505594743021),\n",
       " (120.0, 96.45556121046269),\n",
       " (140.0, 133.7030249046363),\n",
       " (140.0, 133.70317284652117),\n",
       " (200.0, 244.3748078514624)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ais = np.argsort(frecency_points)\n",
    "zip(frecency_points[ais], model.W[ais])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still, the model is correct most of the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:17:04.078878Z",
     "start_time": "2018-07-06T00:17:03.197775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9872"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = sample_suggestions(10000)\n",
    "rank_accuracy(y, model.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side note: Evaluation during training in production\n",
    "\n",
    "If we only use 400 data points for validating the current model, then this is not enough to properly assess the model quality.\n",
    "The accuracies jump too much.\n",
    "However, this evaluation could still be used to test that the model is not completely off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:17:38.255248Z",
     "start_time": "2018-07-06T00:17:04.080871Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.,   6.,   8.,  59.,  85., 119., 382., 184., 100.,  54.]),\n",
       " array([0.9675 , 0.97075, 0.974  , 0.97725, 0.9805 , 0.98375, 0.987  ,\n",
       "        0.99025, 0.9935 , 0.99675, 1.     ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X, y = sample_suggestions(1000 * 400)\n",
    "accuracies = []\n",
    "\n",
    "for i in range(0, len(X) - 400, 400):\n",
    "    Xi, yi = X[i:i+400], y[i:i+400]\n",
    "    acc = rank_accuracy(yi, model.predict(Xi))\n",
    "    accuracies.append(acc)\n",
    "    \n",
    "plt.hist(sorted(accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency\n",
    "\n",
    "We still need to take into account that users visit links more than once.\n",
    "How often a user visits a link is sampled from an exponential distribution in this simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:17:38.509711Z",
     "start_time": "2018-07-06T00:17:38.257225Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([559., 226., 131.,  44.,  22.,   5.,   7.,   4.,   1.,   1.]),\n",
       " array([ 0. ,  5.5, 11. , 16.5, 22. , 27.5, 33. , 38.5, 44. , 49.5, 55. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "frequencies = np.int32(np.random.exponential(7, size=(1000)))\n",
    "plt.hist(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:17:38.536531Z",
     "start_time": "2018-07-06T00:17:38.512230Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_url_features(num_samples):\n",
    "    frequencies = np.int32(np.random.exponential(7, size=num_samples)) + 1\n",
    "    frequencies = np.int32(np.ones(num_samples))\n",
    "    X = []\n",
    "    \n",
    "    for frequency in frequencies:\n",
    "        num_sampled = min(10, frequency)\n",
    "        features = sample_weighted(num_sampled, weights).sum(axis=0)\n",
    "        X.append(frequency / num_sampled * features)\n",
    "        \n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:18:45.118445Z",
     "start_time": "2018-07-06T00:17:38.538528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training: 6.53765 loss, 0.893 accuracy\n",
      "[ModelCheckpoint] New best model with 0.89780 validation accuracy\n",
      "[2/48] training: 2.03379 loss, 0.931 accuracy\n",
      "[ModelCheckpoint] New best model with 0.92590 validation accuracy\n",
      "[3/48] training: 0.89471 loss, 0.956 accuracy\n",
      "[ModelCheckpoint] New best model with 0.95630 validation accuracy\n",
      "[4/48] training: 0.51674 loss, 0.964 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96420 validation accuracy\n",
      "[5/48] training: 0.45467 loss, 0.966 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96470 validation accuracy\n",
      "[6/48] training: 0.39497 loss, 0.962 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[7/48] training: 0.18825 loss, 0.965 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96640 validation accuracy\n",
      "[8/48] training: 0.17068 loss, 0.968 accuracy\n",
      "validation: 0.960 accuracy\n",
      "[9/48] training: 0.11503 loss, 0.963 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[10/48] training: 0.13593 loss, 0.959 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[11/48] training: 0.15025 loss, 0.953 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[12/48] training: 0.10305 loss, 0.962 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[13/48] training: 0.12643 loss, 0.964 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96820 validation accuracy\n",
      "[14/48] training: 0.07054 loss, 0.970 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[15/48] training: 0.04288 loss, 0.962 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[16/48] training: 0.04654 loss, 0.966 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[17/48] training: 0.05236 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[18/48] training: 0.08442 loss, 0.965 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[19/48] training: 0.02441 loss, 0.967 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[20/48] training: 0.03805 loss, 0.962 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[21/48] training: 0.05119 loss, 0.963 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[22/48] training: 0.03019 loss, 0.966 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[23/48] training: 0.02779 loss, 0.968 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[24/48] training: 0.02944 loss, 0.966 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[25/48] training: 0.03325 loss, 0.968 accuracy\n",
      "validation: 0.967 accuracy\n",
      "[26/48] training: 0.02555 loss, 0.963 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[27/48] training: 0.04733 loss, 0.965 accuracy\n",
      "validation: 0.968 accuracy\n",
      "[28/48] training: 0.02080 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[29/48] training: 0.01729 loss, 0.968 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[30/48] training: 0.03026 loss, 0.963 accuracy\n",
      "validation: 0.967 accuracy\n",
      "[31/48] training: 0.03995 loss, 0.960 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[32/48] training: 0.01271 loss, 0.971 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[33/48] training: 0.02525 loss, 0.965 accuracy\n",
      "validation: 0.968 accuracy\n",
      "[34/48] training: 0.01476 loss, 0.964 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[35/48] training: 0.00779 loss, 0.972 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[36/48] training: 0.01397 loss, 0.968 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[37/48] training: 0.00770 loss, 0.965 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[38/48] training: 0.00373 loss, 0.964 accuracy\n",
      "validation: 0.961 accuracy\n",
      "[39/48] training: 0.00406 loss, 0.967 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[40/48] training: 0.01306 loss, 0.966 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[41/48] training: 0.00694 loss, 0.965 accuracy\n",
      "validation: 0.968 accuracy\n",
      "[42/48] training: 0.00515 loss, 0.963 accuracy\n",
      "validation: 0.962 accuracy\n",
      "[43/48] training: 0.00242 loss, 0.967 accuracy\n",
      "validation: 0.967 accuracy\n",
      "[44/48] training: 0.00685 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[45/48] training: 0.00476 loss, 0.963 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[46/48] training: 0.00419 loss, 0.965 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[47/48] training: 0.00202 loss, 0.962 accuracy\n",
      "validation: 0.962 accuracy\n",
      "[48/48] training: 0.00354 loss, 0.964 accuracy\n",
      "validation: 0.967 accuracy\n"
     ]
    }
   ],
   "source": [
    "model = SVMRanking(delta=0.)\n",
    "model.fit(data_generator=sample_suggestions,\n",
    "          optimizer=GradientDescent(30.),\n",
    "          num_iterations=48,\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions, 10000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning\n",
    "\n",
    "To implement a federated version of the model above, we have to create a `Client` class that completely encapsulates training data. Only the `Client` can compute gradients based on its own data. While the `Server` is the main class for controlling the training process, it can only request gradients from clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:18:45.158904Z",
     "start_time": "2018-07-06T00:18:45.120708Z"
    }
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:40:18.905134Z",
     "start_time": "2018-07-06T00:40:18.862878Z"
    }
   },
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self, clients):\n",
    "        self.clients = clients\n",
    "        \n",
    "        num_features = len(frecency_points)\n",
    "        self.W = np.int32(frecency_points + (np.random.random(size=(num_features)) - 0.5) * 100)\n",
    "    \n",
    "    def fit(self, optimizer, num_iterations, num_clients_per_iteration, constraints=[], callbacks=[]):\n",
    "        for j in range(num_iterations):\n",
    "            clients = random.sample(self.clients, num_clients_per_iteration)\n",
    "            updates, losses = zip(*[client.request_update(self) for client in clients])\n",
    "            \n",
    "            gradient = np.mean(updates, axis=0)\n",
    "            loss = np.mean(losses, axis=0)\n",
    "            \n",
    "            print(\"[%d/%d] training loss across clients %.5f\" % (j + 1, num_iterations, loss))\n",
    "            \n",
    "            for callback in callbacks:\n",
    "                callback(self)\n",
    "            \n",
    "            self.W += np.int32(optimizer(gradient))\n",
    "            \n",
    "            for constraint in constraints:\n",
    "                self.W = constraint(self.W)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        \n",
    "        for x in X:\n",
    "            scores = x.dot(self.W)\n",
    "            preds.append(scores)\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:18:45.381044Z",
     "start_time": "2018-07-06T00:18:45.278291Z"
    }
   },
   "outputs": [],
   "source": [
    "class AnalyticalClient:\n",
    "    def __init__(self, data_generator, delta=0):\n",
    "        self.data_generator = data_generator\n",
    "        self.delta = 0\n",
    "    \n",
    "    def request_update(self, model):\n",
    "        X, y = self.data_generator()\n",
    "        preds = model.predict(X)\n",
    "        \n",
    "        num_features = X[0].shape[1]\n",
    "        gradient = np.zeros(num_features)\n",
    "        loss = 0\n",
    "\n",
    "        for xi, pi, yi in zip(X, preds, y):\n",
    "            correct = yi.argmax()\n",
    "            score_correct = pi[correct]\n",
    "\n",
    "            for i, predicted_score in enumerate(pi):\n",
    "                gradient -= xi[i] * max(0, predicted_score + self.delta - score_correct)\n",
    "            \n",
    "            loss += svm_loss(pi, yi)\n",
    "                \n",
    "        gradient /= len(X)\n",
    "        loss /= len(X)\n",
    "        \n",
    "        return gradient, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:39:55.750972Z",
     "start_time": "2018-07-06T00:39:55.712035Z"
    }
   },
   "outputs": [],
   "source": [
    "class FrecencyConstraints:\n",
    "    def __call__(self, gradient):\n",
    "        return gradient - min(0, gradient.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many data points a user has in each round is sampled from the following exponential distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:18:45.929414Z",
     "start_time": "2018-07-06T00:18:45.605254Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([723.,   0., 200.,   0.,  60.,   0.,  13.,   0.,   2.,   2.]),\n",
       " array([2. , 2.5, 3. , 3.5, 4. , 4.5, 5. , 5.5, 6. , 6.5, 7. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_datapoints = np.int32(np.random.exponential(.8, size=(1000))) + 2\n",
    "plt.hist(num_datapoints)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 5000 clients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:18:45.955213Z",
     "start_time": "2018-07-06T00:18:45.931708Z"
    }
   },
   "outputs": [],
   "source": [
    "clients = [AnalyticalClient(lambda: sample_suggestions(np.int32(np.random.exponential(.8)) + 2)) for _ in range(5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:21:03.190202Z",
     "start_time": "2018-07-06T00:20:38.939491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training loss across clients 12.50804\n",
      "[ModelCheckpoint] New best model with 0.75240 validation accuracy\n",
      "[2/48] training loss across clients 54.66287\n",
      "validation: 0.591 accuracy\n",
      "[3/48] training loss across clients 89.68266\n",
      "[ModelCheckpoint] New best model with 0.82900 validation accuracy\n",
      "[4/48] training loss across clients 6.24904\n",
      "[ModelCheckpoint] New best model with 0.97820 validation accuracy\n",
      "[5/48] training loss across clients 5.24104\n",
      "validation: 0.975 accuracy\n",
      "[6/48] training loss across clients 2.98337\n",
      "[ModelCheckpoint] New best model with 0.97940 validation accuracy\n",
      "[7/48] training loss across clients 1.87258\n",
      "validation: 0.979 accuracy\n",
      "[8/48] training loss across clients 1.57953\n",
      "[ModelCheckpoint] New best model with 0.98100 validation accuracy\n",
      "[9/48] training loss across clients 4.44021\n",
      "validation: 0.979 accuracy\n",
      "[10/48] training loss across clients 3.73792\n",
      "validation: 0.979 accuracy\n",
      "[11/48] training loss across clients 1.19375\n",
      "[ModelCheckpoint] New best model with 0.98160 validation accuracy\n",
      "[12/48] training loss across clients 1.76146\n",
      "validation: 0.980 accuracy\n",
      "[13/48] training loss across clients 2.25171\n",
      "[ModelCheckpoint] New best model with 0.98540 validation accuracy\n",
      "[14/48] training loss across clients 1.12688\n",
      "validation: 0.977 accuracy\n",
      "[15/48] training loss across clients 1.52021\n",
      "validation: 0.982 accuracy\n",
      "[16/48] training loss across clients 0.87562\n",
      "validation: 0.981 accuracy\n",
      "[17/48] training loss across clients 0.77708\n",
      "validation: 0.980 accuracy\n",
      "[18/48] training loss across clients 0.84333\n",
      "validation: 0.980 accuracy\n",
      "[19/48] training loss across clients 0.33417\n",
      "validation: 0.976 accuracy\n",
      "[20/48] training loss across clients 0.35042\n",
      "validation: 0.980 accuracy\n",
      "[21/48] training loss across clients 0.59517\n",
      "validation: 0.979 accuracy\n",
      "[22/48] training loss across clients 0.84062\n",
      "validation: 0.981 accuracy\n",
      "[23/48] training loss across clients 0.52883\n",
      "validation: 0.980 accuracy\n",
      "[24/48] training loss across clients 0.64308\n",
      "validation: 0.981 accuracy\n",
      "[25/48] training loss across clients 0.48588\n",
      "validation: 0.981 accuracy\n",
      "[26/48] training loss across clients 0.54479\n",
      "validation: 0.982 accuracy\n",
      "[27/48] training loss across clients 0.16538\n",
      "validation: 0.981 accuracy\n",
      "[28/48] training loss across clients 0.42625\n",
      "validation: 0.981 accuracy\n",
      "[29/48] training loss across clients 0.42633\n",
      "validation: 0.983 accuracy\n",
      "[30/48] training loss across clients 0.21946\n",
      "validation: 0.985 accuracy\n",
      "[31/48] training loss across clients 0.18667\n",
      "validation: 0.981 accuracy\n",
      "[32/48] training loss across clients 0.27292\n",
      "validation: 0.981 accuracy\n",
      "[33/48] training loss across clients 0.12708\n",
      "validation: 0.981 accuracy\n",
      "[34/48] training loss across clients 0.10725\n",
      "validation: 0.981 accuracy\n",
      "[35/48] training loss across clients 0.19175\n",
      "validation: 0.981 accuracy\n",
      "[36/48] training loss across clients 0.11417\n",
      "validation: 0.975 accuracy\n",
      "[37/48] training loss across clients 0.11563\n",
      "validation: 0.981 accuracy\n",
      "[38/48] training loss across clients 0.06958\n",
      "validation: 0.982 accuracy\n",
      "[39/48] training loss across clients 0.13962\n",
      "validation: 0.982 accuracy\n",
      "[40/48] training loss across clients 0.29988\n",
      "validation: 0.982 accuracy\n",
      "[41/48] training loss across clients 0.06875\n",
      "validation: 0.981 accuracy\n",
      "[42/48] training loss across clients 0.08221\n",
      "validation: 0.977 accuracy\n",
      "[43/48] training loss across clients 0.18083\n",
      "validation: 0.981 accuracy\n",
      "[44/48] training loss across clients 0.06883\n",
      "validation: 0.982 accuracy\n",
      "[45/48] training loss across clients 0.14589\n",
      "validation: 0.982 accuracy\n",
      "[46/48] training loss across clients 0.12354\n",
      "validation: 0.980 accuracy\n",
      "[47/48] training loss across clients 0.10246\n",
      "validation: 0.978 accuracy\n",
      "[48/48] training loss across clients 0.04938\n",
      "validation: 0.980 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "server = Server(clients)\n",
    "server.fit(optimizer=GradientDescent(30.),\n",
    "          num_iterations=48,\n",
    "           num_clients_per_iteration=400,\n",
    "           constraints=[FrecencyConstraints()],\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions, 5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "=> The model quality improved from 70% to >97% validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:21:03.240159Z",
     "start_time": "2018-07-06T00:21:03.192921Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.0, 0),\n",
       " (14.0, 151),\n",
       " (20.0, 149),\n",
       " (36.0, 144),\n",
       " (42.0, 564),\n",
       " (60.0, 561),\n",
       " (60.0, 567),\n",
       " (70.0, 775),\n",
       " (84.0, 826),\n",
       " (98.0, 856),\n",
       " (100.0, 855),\n",
       " (120.0, 967),\n",
       " (140.0, 1018),\n",
       " (140.0, 1018),\n",
       " (200.0, 1123)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(frecency_points[ais], server.W[ais])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With RProp\n",
    "\n",
    "[RProp](https://florian.github.io/rprop/) is a gradient descent variation that ignores the magnitude of the gradient.\n",
    "The general motivation for this is that the mangitude can be misleading since it does not have to contain useful information for the step size.\n",
    "\n",
    "The motivation for using RProp in our case is a little bit different: Since we do not collect any training data at all, we have no idea how large the gradient mangitudes are going to be. This is problematic because it makes it very hard to properly configure the learning rate beforehand.\n",
    "To deal with this, we can use RProp to only take into account the signs of gradients.\n",
    "\n",
    "This also makes updates much easier to interpret: They change each frecency weight between 1 and 3, depending on how strong the feedback signal for that weight has been in the past."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:19:34.066635Z",
     "start_time": "2018-07-06T00:19:10.092005Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training loss across clients 12.50804\n",
      "[ModelCheckpoint] New best model with 0.75240 validation accuracy\n",
      "[2/48] training loss across clients 13.21671\n",
      "[ModelCheckpoint] New best model with 0.75560 validation accuracy\n",
      "[3/48] training loss across clients 10.19690\n",
      "[ModelCheckpoint] New best model with 0.75900 validation accuracy\n",
      "[4/48] training loss across clients 8.77127\n",
      "[ModelCheckpoint] New best model with 0.79860 validation accuracy\n",
      "[5/48] training loss across clients 8.40608\n",
      "validation: 0.797 accuracy\n",
      "[6/48] training loss across clients 6.13325\n",
      "[ModelCheckpoint] New best model with 0.80240 validation accuracy\n",
      "[7/48] training loss across clients 5.91335\n",
      "validation: 0.799 accuracy\n",
      "[8/48] training loss across clients 5.21768\n",
      "[ModelCheckpoint] New best model with 0.86460 validation accuracy\n",
      "[9/48] training loss across clients 4.51546\n",
      "[ModelCheckpoint] New best model with 0.87060 validation accuracy\n",
      "[10/48] training loss across clients 4.57298\n",
      "validation: 0.869 accuracy\n",
      "[11/48] training loss across clients 3.27062\n",
      "validation: 0.868 accuracy\n",
      "[12/48] training loss across clients 2.92000\n",
      "[ModelCheckpoint] New best model with 0.87180 validation accuracy\n",
      "[13/48] training loss across clients 2.19942\n",
      "[ModelCheckpoint] New best model with 0.87400 validation accuracy\n",
      "[14/48] training loss across clients 1.15423\n",
      "[ModelCheckpoint] New best model with 0.90580 validation accuracy\n",
      "[15/48] training loss across clients 1.24329\n",
      "[ModelCheckpoint] New best model with 0.91460 validation accuracy\n",
      "[16/48] training loss across clients 1.07704\n",
      "[ModelCheckpoint] New best model with 0.93380 validation accuracy\n",
      "[17/48] training loss across clients 0.71725\n",
      "validation: 0.934 accuracy\n",
      "[18/48] training loss across clients 0.50917\n",
      "[ModelCheckpoint] New best model with 0.95640 validation accuracy\n",
      "[19/48] training loss across clients 0.65358\n",
      "validation: 0.955 accuracy\n",
      "[20/48] training loss across clients 0.67250\n",
      "validation: 0.953 accuracy\n",
      "[21/48] training loss across clients 0.59387\n",
      "validation: 0.951 accuracy\n",
      "[22/48] training loss across clients 0.40542\n",
      "validation: 0.951 accuracy\n",
      "[23/48] training loss across clients 0.34467\n",
      "[ModelCheckpoint] New best model with 0.95820 validation accuracy\n",
      "[24/48] training loss across clients 0.12733\n",
      "validation: 0.958 accuracy\n",
      "[25/48] training loss across clients 0.14521\n",
      "[ModelCheckpoint] New best model with 0.96160 validation accuracy\n",
      "[26/48] training loss across clients 0.05458\n",
      "validation: 0.959 accuracy\n",
      "[27/48] training loss across clients 0.20719\n",
      "validation: 0.869 accuracy\n",
      "[28/48] training loss across clients 0.01875\n",
      "[ModelCheckpoint] New best model with 1.00000 validation accuracy\n",
      "[29/48] training loss across clients 0.16475\n",
      "validation: 0.924 accuracy\n",
      "[30/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[31/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[32/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[33/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[34/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[35/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[36/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[37/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[38/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[39/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[40/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[41/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[42/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[43/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[44/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[45/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[46/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[47/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[48/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "opt = opt = RProp(2., len(frecency_points), min_value=1, max_value=3, alpha=2., beta=0.6)\n",
    "server = Server(clients)\n",
    "server.fit(optimizer=opt,\n",
    "          num_iterations=48,\n",
    "           num_clients_per_iteration=400,\n",
    "           constraints=[FrecencyConstraints()],\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions, 5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:19:53.747166Z",
     "start_time": "2018-07-06T00:19:53.706820Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 2., 3., 3., 3., 2., 2., 3., 2., 2., 3., 3., 2., 2., 3.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:19:54.541101Z",
     "start_time": "2018-07-06T00:19:54.517385Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.0, 0),\n",
       " (14.0, 22),\n",
       " (20.0, 24),\n",
       " (36.0, 26),\n",
       " (42.0, 37),\n",
       " (60.0, 98),\n",
       " (60.0, 98),\n",
       " (70.0, 104),\n",
       " (84.0, 105),\n",
       " (98.0, 107),\n",
       " (100.0, 109),\n",
       " (120.0, 140),\n",
       " (140.0, 142),\n",
       " (140.0, 142),\n",
       " (200.0, 203)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(frecency_points[ais], server.W[ais])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even in the simulation this works a bit better. It's the only optimizer that reaches a perfect score. In a real life application, it is also much more practical, as explained above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With numerical gradient computation\n",
    "\n",
    "So far all simulations were based on the fact that we knew how to analytically derive the gradient.\n",
    "This is not the case for the actual addon, which uses a simple [finite difference method](https://en.wikipedia.org/wiki/Finite_difference_method) of computing the gradient.\n",
    "To make sure the simulations still work, the following reconstructs the important part of the client-side code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:40:25.916393Z",
     "start_time": "2018-07-06T00:40:25.894816Z"
    }
   },
   "outputs": [],
   "source": [
    "def full_loss(model, loss_fn, X, y):\n",
    "    preds = model.predict(X)\n",
    "    return sum([loss_fn(pi, yi) for pi, yi in zip(preds, y)]) / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:40:26.344533Z",
     "start_time": "2018-07-06T00:40:26.311489Z"
    }
   },
   "outputs": [],
   "source": [
    "class NumericalClient:\n",
    "    def __init__(self, data_generator, delta=0):\n",
    "        self.data_generator = data_generator\n",
    "        self.delta = 0\n",
    "    \n",
    "    def request_update(self, model, eps=1):\n",
    "        X, y = self.data_generator()\n",
    "        loss = full_loss(model, svm_loss, X, y)\n",
    "        \n",
    "        num_features = X[0].shape[1]\n",
    "        gradient = []\n",
    "        \n",
    "        for i in range(num_features):\n",
    "            model.W[i] -= eps\n",
    "            loss1 = full_loss(model, svm_loss, X, y)\n",
    "            \n",
    "            model.W[i] += 2 * eps\n",
    "            loss2 = full_loss(model, svm_loss, X, y)\n",
    "            \n",
    "            finite_difference = (loss1 - loss2) / (2 * eps)\n",
    "            gradient.append(finite_difference)\n",
    "            \n",
    "            model.W[i] -= eps\n",
    "        \n",
    "        return gradient, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:40:26.743318Z",
     "start_time": "2018-07-06T00:40:26.677818Z"
    }
   },
   "outputs": [],
   "source": [
    "clients = [NumericalClient(lambda: sample_suggestions(np.int32(np.random.exponential(.8)) + 2)) for _ in range(5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:41:09.911718Z",
     "start_time": "2018-07-06T00:40:27.554833Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training loss across clients 12.50804\n",
      "[ModelCheckpoint] New best model with 0.75240 validation accuracy\n",
      "[2/48] training loss across clients 12.14904\n",
      "[ModelCheckpoint] New best model with 0.75880 validation accuracy\n",
      "[3/48] training loss across clients 8.42656\n",
      "[ModelCheckpoint] New best model with 0.80900 validation accuracy\n",
      "[4/48] training loss across clients 6.27468\n",
      "[ModelCheckpoint] New best model with 0.81660 validation accuracy\n",
      "[5/48] training loss across clients 4.96587\n",
      "[ModelCheckpoint] New best model with 0.88140 validation accuracy\n",
      "[6/48] training loss across clients 2.97904\n",
      "[ModelCheckpoint] New best model with 0.88820 validation accuracy\n",
      "[7/48] training loss across clients 1.94895\n",
      "[ModelCheckpoint] New best model with 0.88920 validation accuracy\n",
      "[8/48] training loss across clients 0.97425\n",
      "[ModelCheckpoint] New best model with 0.96900 validation accuracy\n",
      "[9/48] training loss across clients 0.75292\n",
      "[ModelCheckpoint] New best model with 0.99020 validation accuracy\n",
      "[10/48] training loss across clients 0.71158\n",
      "validation: 0.988 accuracy\n",
      "[11/48] training loss across clients 0.38775\n",
      "[ModelCheckpoint] New best model with 1.00000 validation accuracy\n",
      "[12/48] training loss across clients 0.37250\n",
      "validation: 1.000 accuracy\n",
      "[13/48] training loss across clients 0.15058\n",
      "validation: 1.000 accuracy\n",
      "[14/48] training loss across clients 0.01500\n",
      "validation: 1.000 accuracy\n",
      "[15/48] training loss across clients 0.11458\n",
      "validation: 1.000 accuracy\n",
      "[16/48] training loss across clients 0.08892\n",
      "validation: 1.000 accuracy\n",
      "[17/48] training loss across clients 0.09775\n",
      "validation: 1.000 accuracy\n",
      "[18/48] training loss across clients 0.00750\n",
      "validation: 1.000 accuracy\n",
      "[19/48] training loss across clients 0.06267\n",
      "validation: 1.000 accuracy\n",
      "[20/48] training loss across clients 0.02000\n",
      "validation: 1.000 accuracy\n",
      "[21/48] training loss across clients 0.12208\n",
      "validation: 1.000 accuracy\n",
      "[22/48] training loss across clients 0.05500\n",
      "validation: 1.000 accuracy\n",
      "[23/48] training loss across clients 0.06517\n",
      "validation: 1.000 accuracy\n",
      "[24/48] training loss across clients 0.00937\n",
      "validation: 1.000 accuracy\n",
      "[25/48] training loss across clients 0.06004\n",
      "validation: 1.000 accuracy\n",
      "[26/48] training loss across clients 0.00625\n",
      "validation: 1.000 accuracy\n",
      "[27/48] training loss across clients 0.05625\n",
      "validation: 1.000 accuracy\n",
      "[28/48] training loss across clients 0.01125\n",
      "validation: 1.000 accuracy\n",
      "[29/48] training loss across clients 0.04833\n",
      "validation: 1.000 accuracy\n",
      "[30/48] training loss across clients 0.01000\n",
      "validation: 1.000 accuracy\n",
      "[31/48] training loss across clients 0.06308\n",
      "validation: 1.000 accuracy\n",
      "[32/48] training loss across clients 0.00375\n",
      "validation: 1.000 accuracy\n",
      "[33/48] training loss across clients 0.09104\n",
      "validation: 1.000 accuracy\n",
      "[34/48] training loss across clients 0.07342\n",
      "validation: 1.000 accuracy\n",
      "[35/48] training loss across clients 0.03238\n",
      "validation: 1.000 accuracy\n",
      "[36/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[37/48] training loss across clients 0.07209\n",
      "validation: 1.000 accuracy\n",
      "[38/48] training loss across clients 0.00250\n",
      "validation: 1.000 accuracy\n",
      "[39/48] training loss across clients 0.04275\n",
      "validation: 1.000 accuracy\n",
      "[40/48] training loss across clients 0.00333\n",
      "validation: 1.000 accuracy\n",
      "[41/48] training loss across clients 0.12792\n",
      "validation: 1.000 accuracy\n",
      "[42/48] training loss across clients 0.05083\n",
      "validation: 1.000 accuracy\n",
      "[43/48] training loss across clients 0.04042\n",
      "validation: 1.000 accuracy\n",
      "[44/48] training loss across clients 0.00313\n",
      "validation: 1.000 accuracy\n",
      "[45/48] training loss across clients 0.08525\n",
      "validation: 1.000 accuracy\n",
      "[46/48] training loss across clients 0.05071\n",
      "validation: 1.000 accuracy\n",
      "[47/48] training loss across clients 0.05094\n",
      "validation: 1.000 accuracy\n",
      "[48/48] training loss across clients 0.00458\n",
      "validation: 1.000 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "opt = opt = RProp(2., len(frecency_points), min_value=1, max_value=3, alpha=2., beta=0.6)\n",
    "server = Server(clients)\n",
    "server.fit(optimizer=opt,\n",
    "          num_iterations=48,\n",
    "           num_clients_per_iteration=400,\n",
    "           constraints=[FrecencyConstraints()],\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions, 5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:41:09.953946Z",
     "start_time": "2018-07-06T00:41:09.913793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 3., 2., 3., 3., 3., 1., 3., 3., 3., 1., 1., 2., 1., 3.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.learning_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T00:41:10.063705Z",
     "start_time": "2018-07-06T00:41:09.955859Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.0, 0),\n",
       " (14.0, 46),\n",
       " (20.0, 48),\n",
       " (36.0, 52),\n",
       " (42.0, 54),\n",
       " (60.0, 107),\n",
       " (60.0, 106),\n",
       " (70.0, 119),\n",
       " (84.0, 126),\n",
       " (98.0, 131),\n",
       " (100.0, 135),\n",
       " (120.0, 164),\n",
       " (140.0, 183),\n",
       " (140.0, 185),\n",
       " (200.0, 214)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(frecency_points[ais], server.W[ais])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model still converges nicely with this method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes \n",
    "\n",
    "Simplifications made:\n",
    "\n",
    "- All users sample from the same distribution\n",
    "- `ModelCheckpoint` cannot be based on validation data in the actual implementation\n",
    "- Users should run more than one SGD iteration locally\n",
    "\n",
    "## To make fitting easier\n",
    "\n",
    "- Fair initialization\n",
    "- Normalize data (0-center)\n",
    "- Remove features with a value of 0\n",
    "\n",
    "## Still missing\n",
    "\n",
    "- Implement frequency part (switch from one-hot encoding to up to sum of 10 and add multiplicative factor)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "1162px",
    "left": "0px",
    "right": "1494px",
    "top": "160px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
