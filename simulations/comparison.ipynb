{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.frecency import sample, frecency_points\n",
    "from data.frecency import sample_suggestions_normal as sample_suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizers import GradientDescent, AdaptiveGradientDescent, DecayedGradientDescent, RProp, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointwise ranking\n",
    "\n",
    "The task in this study is pointwise ranking. Each item will be given a score by the model, which will be used for ranking all items. Since the score is a real number, the model that is used in this study is a regression function. Hinge loss, or also known as SVM loss, is used in the model optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_loss(preds, ys, delta=0):\n",
    "    correct = ys.argmax()\n",
    "    score_correct = preds[correct]\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for i, pred in enumerate(preds):\n",
    "        loss += max(0, pred + delta - score_correct)            \n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMRanking:\n",
    "    def __init__(self, delta):\n",
    "        self.delta = delta\n",
    "        \n",
    "    def fit(self, data_generator, optimizer, num_iterations=10, callbacks=[]):\n",
    "        X, y = data_generator(2)\n",
    "        num_features = X[0].shape[1]\n",
    "        self.W = frecency_points + (np.random.random(size=(num_features)) - 0.5) * 100\n",
    "        self.loss = []\n",
    "        \n",
    "        for j in range(num_iterations):\n",
    "            X, y = data_generator(4000)\n",
    "            \n",
    "            preds = self.predict(X)\n",
    "            gradient = np.zeros(num_features)\n",
    "\n",
    "            for xi, pi, yi in zip(X, preds, y):\n",
    "                correct = yi.argmax()\n",
    "                score_correct = pi[correct]\n",
    "\n",
    "                for i, predicted_score in enumerate(pi):\n",
    "                    gradient -= xi[i] * max(0, predicted_score + self.delta - score_correct)\n",
    "            \n",
    "            gradient /= len(X)\n",
    "            \n",
    "            loss = np.mean([svm_loss(pi, yi) for pi, yi in zip(self.predict(X), y)])\n",
    "            accuracy = rank_accuracy(y, model.predict(X))\n",
    "            \n",
    "            print(\"[%d/%d] training: %.5f loss, %.3f accuracy\" % (j + 1, num_iterations, loss, accuracy))\n",
    "            \n",
    "            for callback in callbacks:\n",
    "                callback(self)\n",
    "            \n",
    "            self.W += optimizer(gradient)\n",
    "            self.loss.append(loss)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        \n",
    "        for x in X:\n",
    "            scores = x.dot(self.W)\n",
    "            preds.append(scores)\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two or more items can have the same score. However, there is only one correct answer. The correct answer should be the one that is used to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_accuracy(y, preds):\n",
    "    correct = 0.\n",
    "    \n",
    "    for yi, pi in zip(y, preds):\n",
    "        if yi[pi.argmax()] == yi.max():\n",
    "            correct += 1\n",
    "            \n",
    "    return correct / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training in single server setting\n",
    "\n",
    "Training a machine learning model can be performed in a single machine with high computational resource. It can be done by store all the data in one single place and then use the data to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training: 3.80225 loss, 0.787 accuracy\n",
      "[ModelCheckpoint] New best model with 0.79670 validation accuracy\n",
      "[2/48] training: 1.60038 loss, 0.944 accuracy\n",
      "[ModelCheckpoint] New best model with 0.94620 validation accuracy\n",
      "[3/48] training: 0.77972 loss, 0.963 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96370 validation accuracy\n",
      "[4/48] training: 0.63540 loss, 0.964 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96460 validation accuracy\n",
      "[5/48] training: 0.35693 loss, 0.968 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[6/48] training: 0.56707 loss, 0.967 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[7/48] training: 0.39944 loss, 0.965 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96570 validation accuracy\n",
      "[8/48] training: 0.33584 loss, 0.961 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96870 validation accuracy\n",
      "[9/48] training: 0.40017 loss, 0.963 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[10/48] training: 0.25135 loss, 0.967 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[11/48] training: 0.14411 loss, 0.970 accuracy\n",
      "validation: 0.962 accuracy\n",
      "[12/48] training: 0.14909 loss, 0.962 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[13/48] training: 0.15105 loss, 0.965 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[14/48] training: 0.10008 loss, 0.969 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[15/48] training: 0.12976 loss, 0.965 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[16/48] training: 0.11980 loss, 0.970 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[17/48] training: 0.09692 loss, 0.964 accuracy\n",
      "validation: 0.967 accuracy\n",
      "[18/48] training: 0.08039 loss, 0.966 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[19/48] training: 0.09652 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[20/48] training: 0.06384 loss, 0.965 accuracy\n",
      "validation: 0.968 accuracy\n",
      "[21/48] training: 0.05389 loss, 0.962 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[22/48] training: 0.06603 loss, 0.964 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[23/48] training: 0.04978 loss, 0.965 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[24/48] training: 0.05702 loss, 0.961 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[25/48] training: 0.03534 loss, 0.962 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[26/48] training: 0.05088 loss, 0.965 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[27/48] training: 0.04353 loss, 0.960 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[28/48] training: 0.02919 loss, 0.965 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[29/48] training: 0.04597 loss, 0.961 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[30/48] training: 0.04546 loss, 0.965 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[31/48] training: 0.05533 loss, 0.964 accuracy\n",
      "validation: 0.968 accuracy\n",
      "[32/48] training: 0.03115 loss, 0.962 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[33/48] training: 0.02815 loss, 0.962 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[34/48] training: 0.01073 loss, 0.969 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[35/48] training: 0.00830 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[36/48] training: 0.03234 loss, 0.966 accuracy\n",
      "validation: 0.962 accuracy\n",
      "[37/48] training: 0.02458 loss, 0.966 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[38/48] training: 0.02474 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[39/48] training: 0.01768 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[40/48] training: 0.01838 loss, 0.966 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[41/48] training: 0.03372 loss, 0.962 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[42/48] training: 0.01719 loss, 0.963 accuracy\n",
      "validation: 0.967 accuracy\n",
      "[43/48] training: 0.00932 loss, 0.964 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[44/48] training: 0.01877 loss, 0.963 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[45/48] training: 0.01093 loss, 0.965 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[46/48] training: 0.00770 loss, 0.963 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[47/48] training: 0.01093 loss, 0.964 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[48/48] training: 0.02531 loss, 0.963 accuracy\n",
      "validation: 0.967 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "model = SVMRanking(delta=0.)\n",
    "model.fit(data_generator=sample_suggestions,\n",
    "          optimizer=GradientDescent(30.),\n",
    "          num_iterations=48,\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "serverGD = model.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the learned model parameters can be compared with the true model parameters. Note that the model is evaluated by ranking the score of the items, not merely comparing the prediction and true score of the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.0, -27.577683512788536),\n",
       " (14.0, -19.160789414213696),\n",
       " (20.0, -28.121019956364485),\n",
       " (36.0, 16.02259171985103),\n",
       " (42.0, 16.14509220149754),\n",
       " (60.0, 16.130068341882502),\n",
       " (60.0, 16.022547162926983),\n",
       " (70.0, 67.2793927943136),\n",
       " (84.0, 67.279392794312),\n",
       " (98.0, 78.81310449761837),\n",
       " (100.0, 78.8131044675263),\n",
       " (120.0, 96.45556121046269),\n",
       " (140.0, 133.70319537993416),\n",
       " (140.0, 133.70319537993416),\n",
       " (200.0, 244.3748078514624)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ais = np.argsort(frecency_points)\n",
    "zip(frecency_points[ais], model.W[ais])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training in federated learning setting\n",
    "\n",
    "In several situations, sometimes the server is not allowed to keep the data. To tackle this issue, training a machine learning model can be performed using federated learning setting. In this setting, the data still can be kept in the clients while the training process is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self, clients):\n",
    "        self.clients = clients\n",
    "        \n",
    "        num_features = len(frecency_points)\n",
    "        self.W = np.int32(frecency_points + (np.random.random(size=(num_features)) - 0.5) * 100)\n",
    "    \n",
    "    def fit(self, optimizer, num_iterations, num_clients_per_iteration, constraints=[], callbacks=[]):\n",
    "        \n",
    "        self.loss = []\n",
    "        for j in range(num_iterations):\n",
    "            clients = random.sample(self.clients, num_clients_per_iteration)\n",
    "            updates, losses = zip(*[client.request_update(self) for client in clients])\n",
    "            \n",
    "            gradient = np.mean(updates, axis=0)\n",
    "            loss = np.mean(losses, axis=0)\n",
    "            \n",
    "            print(\"[%d/%d] training loss across clients %.5f\" % (j + 1, num_iterations, loss))\n",
    "            \n",
    "            for callback in callbacks:\n",
    "                callback(self)\n",
    "            \n",
    "            self.W += np.int32(optimizer(gradient))\n",
    "            self.loss.append(loss)\n",
    "            \n",
    "            for constraint in constraints:\n",
    "                self.W = constraint(self.W)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        \n",
    "        for x in X:\n",
    "            scores = x.dot(self.W)\n",
    "            preds.append(scores)\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyticalClient:\n",
    "    def __init__(self, data_generator, delta=0):\n",
    "        self.data_generator = data_generator\n",
    "        self.delta = 0\n",
    "    \n",
    "    def request_update(self, model):\n",
    "        X, y = self.data_generator()\n",
    "        preds = model.predict(X)\n",
    "        \n",
    "        num_features = X[0].shape[1]\n",
    "        gradient = np.zeros(num_features)\n",
    "        loss = 0\n",
    "\n",
    "        for xi, pi, yi in zip(X, preds, y):\n",
    "            correct = yi.argmax()\n",
    "            score_correct = pi[correct]\n",
    "\n",
    "            for i, predicted_score in enumerate(pi):\n",
    "                gradient -= xi[i] * max(0, predicted_score + self.delta - score_correct)\n",
    "            \n",
    "            loss += svm_loss(pi, yi)\n",
    "                \n",
    "        gradient /= len(X)\n",
    "        loss /= len(X)\n",
    "        \n",
    "        return gradient, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrecencyConstraints:\n",
    "    def __call__(self, gradient):\n",
    "        return gradient - min(0, gradient.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, 5000 clients are used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [AnalyticalClient(lambda: sample_suggestions(np.int32(np.random.exponential(.8)) + 2)) for _ in range(5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training loss across clients 12.50804\n",
      "[ModelCheckpoint] New best model with 0.75240 validation accuracy\n",
      "[2/48] training loss across clients 54.66287\n",
      "validation: 0.591 accuracy\n",
      "[3/48] training loss across clients 89.68266\n",
      "[ModelCheckpoint] New best model with 0.82900 validation accuracy\n",
      "[4/48] training loss across clients 6.24904\n",
      "[ModelCheckpoint] New best model with 0.97820 validation accuracy\n",
      "[5/48] training loss across clients 5.24104\n",
      "validation: 0.975 accuracy\n",
      "[6/48] training loss across clients 2.98337\n",
      "[ModelCheckpoint] New best model with 0.97940 validation accuracy\n",
      "[7/48] training loss across clients 1.87258\n",
      "validation: 0.979 accuracy\n",
      "[8/48] training loss across clients 1.57953\n",
      "[ModelCheckpoint] New best model with 0.98100 validation accuracy\n",
      "[9/48] training loss across clients 4.44021\n",
      "validation: 0.979 accuracy\n",
      "[10/48] training loss across clients 3.73792\n",
      "validation: 0.979 accuracy\n",
      "[11/48] training loss across clients 1.19375\n",
      "[ModelCheckpoint] New best model with 0.98160 validation accuracy\n",
      "[12/48] training loss across clients 1.76146\n",
      "validation: 0.980 accuracy\n",
      "[13/48] training loss across clients 2.25171\n",
      "[ModelCheckpoint] New best model with 0.98540 validation accuracy\n",
      "[14/48] training loss across clients 1.12688\n",
      "validation: 0.977 accuracy\n",
      "[15/48] training loss across clients 1.52021\n",
      "validation: 0.982 accuracy\n",
      "[16/48] training loss across clients 0.87562\n",
      "validation: 0.981 accuracy\n",
      "[17/48] training loss across clients 0.77708\n",
      "validation: 0.980 accuracy\n",
      "[18/48] training loss across clients 0.84333\n",
      "validation: 0.980 accuracy\n",
      "[19/48] training loss across clients 0.33417\n",
      "validation: 0.976 accuracy\n",
      "[20/48] training loss across clients 0.35042\n",
      "validation: 0.980 accuracy\n",
      "[21/48] training loss across clients 0.59517\n",
      "validation: 0.979 accuracy\n",
      "[22/48] training loss across clients 0.84062\n",
      "validation: 0.981 accuracy\n",
      "[23/48] training loss across clients 0.52883\n",
      "validation: 0.980 accuracy\n",
      "[24/48] training loss across clients 0.64308\n",
      "validation: 0.981 accuracy\n",
      "[25/48] training loss across clients 0.48588\n",
      "validation: 0.981 accuracy\n",
      "[26/48] training loss across clients 0.54479\n",
      "validation: 0.982 accuracy\n",
      "[27/48] training loss across clients 0.16538\n",
      "validation: 0.981 accuracy\n",
      "[28/48] training loss across clients 0.42625\n",
      "validation: 0.981 accuracy\n",
      "[29/48] training loss across clients 0.42633\n",
      "validation: 0.983 accuracy\n",
      "[30/48] training loss across clients 0.21946\n",
      "validation: 0.985 accuracy\n",
      "[31/48] training loss across clients 0.18667\n",
      "validation: 0.981 accuracy\n",
      "[32/48] training loss across clients 0.27292\n",
      "validation: 0.981 accuracy\n",
      "[33/48] training loss across clients 0.12708\n",
      "validation: 0.981 accuracy\n",
      "[34/48] training loss across clients 0.10725\n",
      "validation: 0.981 accuracy\n",
      "[35/48] training loss across clients 0.19175\n",
      "validation: 0.981 accuracy\n",
      "[36/48] training loss across clients 0.11417\n",
      "validation: 0.975 accuracy\n",
      "[37/48] training loss across clients 0.11563\n",
      "validation: 0.981 accuracy\n",
      "[38/48] training loss across clients 0.06958\n",
      "validation: 0.982 accuracy\n",
      "[39/48] training loss across clients 0.13962\n",
      "validation: 0.982 accuracy\n",
      "[40/48] training loss across clients 0.29988\n",
      "validation: 0.982 accuracy\n",
      "[41/48] training loss across clients 0.06875\n",
      "validation: 0.981 accuracy\n",
      "[42/48] training loss across clients 0.08221\n",
      "validation: 0.977 accuracy\n",
      "[43/48] training loss across clients 0.18083\n",
      "validation: 0.981 accuracy\n",
      "[44/48] training loss across clients 0.06883\n",
      "validation: 0.982 accuracy\n",
      "[45/48] training loss across clients 0.14589\n",
      "validation: 0.982 accuracy\n",
      "[46/48] training loss across clients 0.12354\n",
      "validation: 0.980 accuracy\n",
      "[47/48] training loss across clients 0.10246\n",
      "validation: 0.978 accuracy\n",
      "[48/48] training loss across clients 0.04938\n",
      "validation: 0.980 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "server = Server(clients)\n",
    "server.fit(optimizer=GradientDescent(30.),\n",
    "          num_iterations=48,\n",
    "           num_clients_per_iteration=400,\n",
    "           constraints=[FrecencyConstraints()],\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions, 5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "federatedGD = server.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.0, 0),\n",
       " (14.0, 151),\n",
       " (20.0, 149),\n",
       " (36.0, 144),\n",
       " (42.0, 564),\n",
       " (60.0, 561),\n",
       " (60.0, 567),\n",
       " (70.0, 775),\n",
       " (84.0, 826),\n",
       " (98.0, 856),\n",
       " (100.0, 855),\n",
       " (120.0, 967),\n",
       " (140.0, 1018),\n",
       " (140.0, 1018),\n",
       " (200.0, 1123)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(frecency_points[ais], server.W[ais])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training in federated learning setting using RProp\n",
    "\n",
    "RProp, or resilient backpropagation, is a learning method that ignores the magnitude of the gradient and only uses the sign of the gradient. The main motivation of RProp is to avoid experimenting different learning rates to train the model. In addition, it can also be used to reduce the size of the data that is sent from clients to the server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training loss across clients 12.50804\n",
      "[ModelCheckpoint] New best model with 0.75240 validation accuracy\n",
      "[2/48] training loss across clients 13.21671\n",
      "[ModelCheckpoint] New best model with 0.75560 validation accuracy\n",
      "[3/48] training loss across clients 10.19690\n",
      "[ModelCheckpoint] New best model with 0.75900 validation accuracy\n",
      "[4/48] training loss across clients 8.77127\n",
      "[ModelCheckpoint] New best model with 0.79860 validation accuracy\n",
      "[5/48] training loss across clients 8.40608\n",
      "validation: 0.797 accuracy\n",
      "[6/48] training loss across clients 6.13325\n",
      "[ModelCheckpoint] New best model with 0.80240 validation accuracy\n",
      "[7/48] training loss across clients 5.91335\n",
      "validation: 0.799 accuracy\n",
      "[8/48] training loss across clients 5.21768\n",
      "[ModelCheckpoint] New best model with 0.86460 validation accuracy\n",
      "[9/48] training loss across clients 4.51546\n",
      "[ModelCheckpoint] New best model with 0.87060 validation accuracy\n",
      "[10/48] training loss across clients 4.57298\n",
      "validation: 0.869 accuracy\n",
      "[11/48] training loss across clients 3.27062\n",
      "validation: 0.868 accuracy\n",
      "[12/48] training loss across clients 2.92000\n",
      "[ModelCheckpoint] New best model with 0.87180 validation accuracy\n",
      "[13/48] training loss across clients 2.19942\n",
      "[ModelCheckpoint] New best model with 0.87400 validation accuracy\n",
      "[14/48] training loss across clients 1.15423\n",
      "[ModelCheckpoint] New best model with 0.90580 validation accuracy\n",
      "[15/48] training loss across clients 1.24329\n",
      "[ModelCheckpoint] New best model with 0.91460 validation accuracy\n",
      "[16/48] training loss across clients 1.07704\n",
      "[ModelCheckpoint] New best model with 0.93380 validation accuracy\n",
      "[17/48] training loss across clients 0.71725\n",
      "validation: 0.934 accuracy\n",
      "[18/48] training loss across clients 0.50917\n",
      "[ModelCheckpoint] New best model with 0.95640 validation accuracy\n",
      "[19/48] training loss across clients 0.65358\n",
      "validation: 0.955 accuracy\n",
      "[20/48] training loss across clients 0.67250\n",
      "validation: 0.953 accuracy\n",
      "[21/48] training loss across clients 0.59387\n",
      "validation: 0.951 accuracy\n",
      "[22/48] training loss across clients 0.40542\n",
      "validation: 0.951 accuracy\n",
      "[23/48] training loss across clients 0.34467\n",
      "[ModelCheckpoint] New best model with 0.95820 validation accuracy\n",
      "[24/48] training loss across clients 0.12733\n",
      "validation: 0.958 accuracy\n",
      "[25/48] training loss across clients 0.14521\n",
      "[ModelCheckpoint] New best model with 0.96160 validation accuracy\n",
      "[26/48] training loss across clients 0.05458\n",
      "validation: 0.959 accuracy\n",
      "[27/48] training loss across clients 0.20719\n",
      "validation: 0.869 accuracy\n",
      "[28/48] training loss across clients 0.01875\n",
      "[ModelCheckpoint] New best model with 1.00000 validation accuracy\n",
      "[29/48] training loss across clients 0.16475\n",
      "validation: 0.924 accuracy\n",
      "[30/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[31/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[32/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[33/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[34/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[35/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[36/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[37/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[38/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[39/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[40/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[41/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[42/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[43/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[44/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[45/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[46/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[47/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[48/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "opt = opt = RProp(2., len(frecency_points), min_value=1, max_value=3, alpha=2., beta=0.6)\n",
    "server = Server(clients)\n",
    "server.fit(optimizer=opt,\n",
    "          num_iterations=48,\n",
    "           num_clients_per_iteration=400,\n",
    "           constraints=[FrecencyConstraints()],\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions, 5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "federatedRProp = server.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.0, 0),\n",
       " (14.0, 22),\n",
       " (20.0, 24),\n",
       " (36.0, 26),\n",
       " (42.0, 37),\n",
       " (60.0, 98),\n",
       " (60.0, 98),\n",
       " (70.0, 104),\n",
       " (84.0, 105),\n",
       " (98.0, 107),\n",
       " (100.0, 109),\n",
       " (120.0, 140),\n",
       " (140.0, 142),\n",
       " (140.0, 142),\n",
       " (200.0, 203)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(frecency_points[ais], server.W[ais])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.DataFrame({\n",
    "    'Server_GD': serverGD,\n",
    "    'Federated_GD': federatedGD,\n",
    "    'Federated_RProp': federatedRProp})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison\n",
    "\n",
    "Learning in different settings can affect the convergence rate of the training process. The higher the convergence rate, the fewer number of iterations are needed to achieve the target. In this study, we are interested in comparing the convergence rate of different settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3XmcU9X5+PHPk2WSWRhWFQQUtCKCCgLFsqi426qo/dWi1gpav9bla11aq7Z+rdba1q9+rWu1WqtWrWK1uLRqrQtQUSkgiCzuIqLIMsMMzJrt+f1xb0JmyMxklkzG3Of9euWV5Obee57cmeTJOefec0RVMcYY412+fAdgjDEmvywRGGOMx1kiMMYYj7NEYIwxHmeJwBhjPM4SgTHGeJwlApN3InKSiHwmIjUickAW608TkXXdEVtHicgDIvKrLNddIyJH5DqmXBCRn4nIH/Mdh+kcSwQe0oO/cG4C/ltVy1R1afMXRURF5Gu5KFhEZrn7v7nZ8hPd5Q/kotz2EJHJIvKKiGwTkWoReVZERnVT2TVpt4SI1Kc9/56q/lpVz+6OWEzuWCIwPcHuwMo8lv8RMENEAmnLzgDez1M8KSIyCXgReBrYFRgOvA0sEJE9urgsEZEm3wluci5T1TJgLXB82rJHurJ8kz+WCAwAIvJfIvKhiFSKyDMisqu7XETkdyKy0f01ulxE9nVf+5aIrHJ/qX4uIj9pYd8+EblKRD519/NnEektIiERqQH8wNsi8lGGbee7D992f4XOSHvtx+7+1ovImWnLQyJyk4isFZENInK3iBS38va/BN4Bjna37wdMBp5pFst0EVkpIlUiMldE9kl77QARecs9FrOBcLNtjxORZe62r4vI/q3Ek+5/gT+r6q2quk1VK1X1KuBN4Bp336tF5Li0sgIisllExrnPv+GWWSUib4vItLR154rI9SKyAKgD2pVcROQaEXnYfTzMrUWd6Tb1bRGRc0Xk6+7/TZWI3NFs+7Pc+LeIyD9FZPf2lG+6iKrazSM3YA1wRIblhwGbgXFACLgdmO++djSwBOgDCLAPMMh9bT1wkPu4LzCuhXLPAj7E+ZIpA/4GPJT2ugJfayXuJq8D04AY8EsgCHwL50usr/v6LThf4v2AXsCzwG9a2Pcs4DXgNGC2u+x84A/Ar4AH3GUjgFrgSLfMn7rvqci9fQpc4r72HSAK/MrddhywETgQJ+nNdP8WoTb+LiVAHDg0w2tnAuvdx1cDj6S9dizwrvt4MFDhHiOfG38FsJP7+lycX/qjgQAQbM//D04yeth9PMz9W92NkwiPAhqAp4Cd3Vg2Aoe465/oHsN93LKvAl7P9+fEizerERiA7wF/UtW3VLURuBKYJCLDcL7QegEjAVHV1aq63t0uCowSkXJV3aKqb7Wy/5tV9WNVrXH3f0qzppj2igK/VNWoqj4H1AB7i4gA/wVcos6v523Ar4FT2tjfHGCaiPTGaRb6c7PXZwD/UNV/qWoUp1+jGKfm8A2cBHCLG88TwKK0bf8L+IOqLlTVuKo+CDS627WmH86X9/oMr60HBriP/wJMF5ES9/lp7jKA04HnVPU5VU2o6r+AxTiJIekBVV2pqjH3vXXWdaraoKov4iTPR1V1o6p+DvwbSJ4Q8EOcBL1aVWM4f6exVivofpYIDDhtz58mn7hf1hXAYFV9BbgDuBPYICL3iEi5u+r/w/lC+VRE5rnt2W3u330cAHbpRMwV7pdHUh1ObWMnnF/SS9ymiCrgBXd5i1S1HvgHzq/SAaq6oLX3oKoJ4DOcX7m7Ap+ravoIjunvd3fgx8l43JiGutu1ZguQAAZleG0QTi0OVf0QWA0c7yaD6WxPBLsDJzcre2qzfX7WRhzttSHtcX2G52Vpsd2aFlclTq1zcBfHY9pgicAAfIHzoQRAREqB/sDnAKp6m6qOx2k+GAFc5i5fpKon4FT7nwIez2b/wG44TTsbMq/eKZtxvmxGq2of99Zbnc7OtvwZ+DHwUIbXmh8jwfky/xzn1/lgd1nSbmmPPwOuT4unj6qWqOqjrQWjqrXAG8DJGV7+LvBy2vNHgVOBE4BVbnJIlv1Qs7JLVfW36UW1FkcOfQb8sFlsxar6ep7i8SxLBN4TFJFw2i2A8+vxTBEZKyIhnCr6QlVd43b0HSgiQZxqfgMQF5EiEfmeiPR2mxO24rRnZ/IocImIDBeRMnf/s5v9om/NBrLsxHR/qd8L/E5EdgYQkcEicnQWm8/DaUO/PcNrjwPHisjh7rH4MU7zzus4X9Yx4EduR+23gYlp294LnOseRxGRUhE5VkR6ZRHTFcBMEfmRiPQSkb7iXJ8wCbg2bb3HcNrkz2N7bQDgYZyawtEi4nf/5tNEZEgWZefa3cCVIjIaQJwTCDIlPZNjlgi85zmcX8zJ2zWq+jLwP8CTOL9u92R7m3o5zhfZFpzmjgqc9nGA7wNrRGQrcC5Oe3Qmf8L5lT0f+AQnmVzYjpivAR50mxC+m8X6l+N0Qr7pxvYSsHdbG6njZVWtzPDaezjv73acWsfxOKdSRlQ1Anwbp+N5C05/wt/Stl2M009wh/v6h+66bVLV13A67L+N87f5FKeNfaqqfpC23nqchDQZmJ22/DOcWsLPgE04v8Ivowd89lV1DnAD8Jj7d1oBfDO/UXmTNG3WNMYY4zV5/1VgjDEmvywRGGOMx1kiMMYYj7NEYIwxHteZKzu7zYABA3TYsGHt3i6RSADg8+Un3+W7/J4QQ77L7wkxeL38nhCDV8tfsmTJZlVt9WJK+IokgmHDhrF48eJ2b1dfXw9AcXFr443lTr7L7wkx5Lv8nhCD18vvCTF4tXwR+bTttaxpyBhjPM8SgTHGeJwlAmOM8bivRB+BMabjYrEYGzZsIBrtihGmOyY5gkHTcfms/K4SDocZMmQIwWCwQ9tbIjCmwG3YsIHy8nJ22mmnvH0RevWsne4oX1WpqKhg3bp1DB8+vEP7sKYhYwpcJBKhf//+eUsCJrdEhP79+9PQ0NDhfVgiMMYDLAkUts7+fS0RNLPssyqWr6vKdxjGGNNtLBE088tnV/Lr51bnOwxjjOk2lgia2VTTSF2kpYm2jDEdEQwGGTduHGPHjmXs2LGsWbMm621nzZrFE0880SVxzJ07l9dfb/9MmMOGDWPz5s0tvr5hwwZOO+009thjD8aPH8+kSZOYM2dOqsy+ffsyfvx49t57bw4++GD+/ve/d/g95IKdNdRMRU2E4qA/32EYU1CKi4t56623uuWsnVgsRiCQ+att7ty5lJWVMXny5C4rT1U58cQTmTlzJn/5izNL6KeffsozzzyTWmfq1Kk8++yz+Hw+li1bxoknnkhxcTGHH354l8XRGZYI0tRH4tRF4jREE/kOxZicuPbZlaz6YmuX7nPUruX84vjR7d4uHo9zxRVXMHfuXBobG7ngggv44Q9/iKpy4YUX8sorrzB8+HDSZ1FcsmQJl156KTU1NQwYMIAHHniAQYMGMW3aNCZPnsyCBQuYPn06I0aM4Fe/+lXqjKmHHnqI+vp67r77bvx+Pw8//DC33347I0eO5Nxzz2Xt2rUA3HLLLUyZMoWKigpOPfVUNm3axMSJE2ltJsdXXnmFoqIizj333NSy3XffnQsvzDwb69ixY7n66qu54447LBH0RBW1jQA0RK1pyJiuVF9fz7hx4wAYPnw4c+bM4b777qN3794sWrSIxsZGpkyZwlFHHcXSpUt57733eOedd9iwYQOjRo3irLPOIhqNcuGFF/L000+z0047MXv2bH7+85/zpz/9CYCqqirmzZsHwJYtW3jzzTcREf74xz9y4403ctNNN3HuuedSVlbGT37yEwBOO+00LrnkEqZOncratWs5+uijWb16Nddeey1Tp07l6quv5h//+Af33HNPi+9t5cqVqfeWrXHjxnHjjTd25FDmhCWCNJW1EcASgSlcHfnl3hUyNQ29+OKLLF++PNX+X11dzQcffMD8+fM59dRT8fv97Lrrrhx22GEAvPfee6xYsYIjjzwScGoUgwYNSu1vxowZqcfr1q1jxowZrF+/nkgkQkvD2L/00kusWrUq9Xzr1q1s27aN+fPn87e//Q2AY489lr59+2b9Xi+44AJee+01ioqKWLRoUcZ1etpc8ZYI0lTUuIkgZk1DxuSaqnL77bdz9NFHN1n+3HPPZTwvXlUZPXo0b7zxRsb9lZaWph5feOGFXHrppUyfPp25c+dyzTXXZNwmkUjwxhtvZBweOttz80ePHs2TTz6Zen7nnXeyefNmJkyY0OI2S5cuZZ999slq/93BzhpKU+HWCCKxBIlEz8rYxhSao48+mrvuuis1BtL7779PbW0tBx98MI899hjxeJz169fz6quvArD33nuzadOmVCKIRqOsXLky476rq6sZPHgwAA8++GBqea9evdi2bVvq+VFHHcUdd9yRer5s2TIADj74YB555BEAnn/+ebZs2dLi+zjssMNoaGjgrrvuSi2rq6trcf3ly5dz3XXXccEFF7S4TnezRJCm0u0jAGi0WoExOXX22WczatQoxo0bx7777ssPf/hDYrEYJ510EnvttRf77bcf5513HocccggARUVFPPHEE1x++eWMGTOGsWPHtngq6DXXXMPJJ5/MQQcdxIABA1LLjz/+eObMmcPYsWP597//zW233cbixYvZf//9GTVqFHfffTcAv/jFL5g/fz7jxo3jxRdfZLfddmvxfYgITz31FPPmzWP48OFMnDiRmTNncsMNN6TWee2111Knj15wwQXcdtttPaajGEB6WltVJhMmTNDumKHsN8+t5g/zPwZg6f8cSd/SonaX2ZnycyHfMeS7/J4QQ77LX7VqFSNHjrSpKgu8/NWrV+/Q3CQiS1S15TYql9UI0iSbhgAaYtZhbIzxBussTlNRs71pyK4lMMakq6ioyNic8/LLL9O/f/88RNR1LBGkqUyvEdgppMaYNP379091JhcaaxpKs7kmQp8SZ4YfSwTGGK+wRJCmsjbC4D5Oh541DRljvMISgasuEqM+GmfXZCKwzmJjjEdYInAlrypO1ggarWnIGOMRlghcyVNHrWnImK5X6PMR+P1+xo4dy7777svxxx9PVZUzy+GaNWsoLi5OXTR37rnnpq4p6ElymghE5BIRWSkiK0TkUREJi8hwEVkoIh+IyGwR6dxVW10keVXx4L7JRGA1AmO6SnLQuWXLlrFs2bIWB4HrCrFYrMXXOpoI2lJcXMyyZctYsWIF/fr1484770y9tueee6be+6pVq3jqqaeabBuP5/+7Jmenj4rIYOBHwChVrReRx4FTgG8Bv1PVx0TkbuAHwF2t7KpbbHabhlJ9BJYITCF6/gr48p2u3efA/eCbv233ZoUyH0FzkyZNYvny5TssDwQCTJ48mQ8//JC5c+dy7bXXMmjQoFSCuPnmm1NDap999tlcfPHFrFmzhmOOOYYDDzyQpUuXMmLECP785z9TUlLS7uPdmlw3DQWAYhEJACXAeuAwIFnPexA4MccxZKWyedOQjTVkTJdJzkcwduxYTjrpJIAm8xEsWrSIe++9l08++YQ5c+ak5iO49957U7/gk/MRPPHEEyxZsoSzzjqLn//856kykvMR/PjHP2bq1Km8+eabLF26lFNOOYUbb7yRYcOGce6553LJJZewbNkyDjroIC666CIuueQSFi1axJNPPsnZZ58NkJqPYOnSpUyfPj2VKNoSj8d5+eWXmT59+g6v1dXV8fLLL7PffvsB8J///Ifrr7+eVatWsWTJEu6//34WLlzIm2++yb333svSpUsBZ/jtc845h+XLl1NeXs7vf//7jv8hWpCzGoGqfi4iNwFrgXrgRWAJUKWqybrbOmBwW/tKJBKp8Vrao6GhIet1N1TVEg74KPY5NYGausYOldnR8nMl3zHku/yeEEO+y1fV7e3SR/86N4W00e5dXFzM4sWLU2PtJBIJ/vnPf/LOO+80mY/gvffeY968ecyYMQMRYeDAgRx66KEkEglWr169w3wEAwcOTL23k08+OfV47dq1fPe73+XLL79MzUeQSCRQ1SbHI9N8BNXV1cyfP58nnniCRCLBN7/5Tfr27UsikWixfb++vj7V9zF+/HgOP/zw1PofffQRBxxwACLCCSecwNFHH83cuXOZOHEiu+++O4lEgn//+9+p6SsBTjrpJObPn8/xxx/P0KFDmTRpEolEgtNOO43bb7+dSy+9dIcYVLXD31m5bBrqC5wADAeqgL8C38ywasY6l4icA5wDMHTo0BxFuV1lXZS+pUH8PiHoEzt91JgcU1VuvfXWHeYjeP7551udj2DBggUZ95c+H8FFF13ExRdfnJqP4Nprr824TSKRYMGCBZ2ajwC294FUV1czffp0fv/736emqtxzzz1ZsmQJ0HTQufTmndaanprH0Z64spXLISaOAD5R1U0AIvI3YDLQR0QCbq1gCPBFpo1V9R7gHnBGH+3MyI3ZbFtVH2enXmGKi4sJB/3E1Ndlo0Xmc+TNnhJDvsvvCTHkq3wRwefz5XX0UWCHGI455hj+8Ic/cMQRRxAMBnn//fcZPHgwhxxyCH/4wx+YNWsWGzduZO7cuXzve99jn332YdOmTSxcuJBJkyYRjUZ5//33GT169A77r66uZujQofh8Ph566KHUMSgvL2fr1q2p9Y466ih+//vfc9lllwHOfARjx47l4IMP5tFHH+Wqq65KzUfQ1jH0+Xz07duX2267jRNOOIHzzz8/tX6m+2RMAIcccgizZs3iyiuvRFV56qmneOihh/D5fKxduzb1nmfPns1BBx2UMQ4R6fD/WC7/M9YC3xCREnFS2OHAKuBV4DvuOjOBp3MYQ9YqayP0c4edDgX9NFqNwJicKpT5CJo74IADGDNmDI899ljW24wbN45Zs2YxceJEDjzwQM4++2wOOOAAAPbZZx8efPBB9t9/fyorKznvvPOy3m+2cjofgYhcC8wAYsBS4GycPoHHgH7ustNVtbHFndA98xFM/s3LTNpzAP/33TFMveEVvj6sH7+bMbbdZXa0/FzJdwz5Lr8nxJDv8m0+gq9u+WvWrOG4445jxYoVba7bmfkIcjr6qKr+AvhFs8UfAxNzWW57qSoVtRH6lzk1gnDQb6ePGmM8w4ahBmojcRpjCfqXJhOBzxKBMaaJfMxHMGzYsKxqA51liQCodC8mS/YRhAN+G2LCGNOEzUdQ4Da7w0sMKAsBbtOQdRYbYzzCEgEZagRBn9UIjDGeYYmA7cNLJDuLQ0G/DUNtjPEMSwRsbxrqX+o2DQXsrCFjjHdYIsBpGioO+iku8gNu05ANOmdMl/r1r3/N6NGj2X///Rk7diwLFy7Md0i88MILTJw4kZEjRzJ27FhmzJiRGmBu1qxZDB8+nDFjxjBixAjOOOMMPv/88zxHnBt21hA0uYYA7DoCY7raG2+8wT/+8Q/eeustQqEQmzdvJhKJZLVtLBYjEOj4V1UsFst4IdeKFSu48MILeeaZZ1IXYj3zzDOsWbMmdSXxjTfeyHe+8x1UlVtuuYVDDz2UFStWUFTUI6ZR6TKWCHATQWl6InCuI1DVnAzwZEy+3PCfG3i38t0u3efIfiO5fOLlra6zfv16+vfvTyjkNL8mh33IZn6Bww47jPvvv5+PP/4Yn89HXV0de++9Nx9//DFr167lggsuYNOmTZSUlHDvvfcycuRIZs2aRb9+/Vi6dCnjxo3jxhtv3PFY3HADP/vZz5pcjZtp+GhwxvG55JJLmDNnDs8//zwnnHBCRw9Xj2RNQ0BFTSP93VNHwekjSChE47kbfsMYLznqqKNYt24dI0aM4Pzzz2fevHlZzy/wi1/8gjFjxjBv3jwAnn32WY4++miCwSDnnHMOt99+O0uWLOGmm27i/PPPT23//vvv89JLL/F///d/GWNauXIl48aNa9f7GDduHO++27WJtCewGgHOWUP7DCpPPQ8Hnb6ChlicooDlSlM42vrlnitlZWUsWrSIBQsW8OqrrzJjxgyuuuqqHeYXGDRoUGqbGTNmNHk8e/ZsDj30UB577DHOP/98ampqeP311zn55JNT6zU2bh+27OSTT8bv92cVX/Kq4bq6Os455xx+8pOfZFwvl2Oz5ZPnE4GqUlHTvI/A+fJviMYpDwfzFZoxBcXv9zNt2jSmTZvGfvvtx5133sno0aN54403Mq6fPr/A9OnTufLKK6msrGTJkiUcdthh1NbW0qdPnxav9k3fPpPRo0fz1ltvMWbMmNRVwzfddBM1NTUtbrN06dKMw0x81Xn+525NY4xIPNGkjyDk1gga7aIyY7rEe++9xwcffJB6vmzZstT8AslEEI1GWblyZcbty8rKmDhxIhdddBHHHXccfr+f8vJyhg8fzl//+lfA+VH39ttvZx3TT3/6U66//npWr16dWlZXV5dxXVXltttuY/369RxzzDFZl/FV4flEUOFeVZy8hgDSmobszCFjukRNTQ1nnnkmo0aNYv/992fVqlX88pe/zHp+AXCahx5++OEmTUaPPPII9913H2PGjGH06NE8/XT205vst99+3HrrrZxxxhmMHDmSKVOmsHr1ak477bTUOpdddlnq9NFFixbx6quvFtwZQ2BNQ1S4VxX3S28aCiSbhqxGYExXGD9+PK+99toOp3EOGDCA+fPn77D+3Llzd1iWPI0z3fDhw3nhhRd2WPeBBx7IKq5jjz2WY489NuNr2e6jEFiNoMYdcC5TjcAGnjPGeIDnawSVmWoE1jRkTMG4//77ufXWW5ssmzJlCnfeeWeeIup5PJ8Ikk1DzS8oA2saMoWjUE97zMaZZ57JzJkzgfxNVZlrnf37FuZRaYeKmgilRf5ULQCsRmAKS1FRERUVFZ5OBoVMVamoqCAcDnd4H1YjqG16VTE4VxaDJQJTGHbZZRc2bNhARUVF3mJIJqF8DdlS6OWHw2GGDBnS4e09nwgqayOpCWmSUk1DNgKpKQCBQIDBgwdTXFyctxjq6+sB8haD18tvi+ebhjbXRBhQ1jQRbL+gzGoExpjC5/lEUFnb2HKNwBKBMcYDPJ0IVJXK2sgOfQRFfh8idtaQMcYbPJ0ItjbEiMa1yamj4HTo2HSVxhiv8HQiaD5pfTpnukpLBMaYwufpRJAcXqJfaWiH14qDfmsaMsZ4grcTQYaripNs3mJjjFd4OxHUtNw0FLIagTHGIzydCCprk01DmfsIGq2PwBjjAZ5OBJtrIvQKBQgFdpzX1M4aMsZ4hacTQWVtpMnw0+nCQZ81DRljPMHTiaCitjFjRzFYZ7Exxju8nQhqIhlPHQU3EVgfgTHGA7ydCGp3HHAuyZqGjDFe4dlEkEgoWzIMQZ0Uss5iY4xH5DQRiEgfEXlCRN4VkdUiMklE+onIv0TkA/e+by5jaMnWhiixhO4w4FxSOOin0WoExhgPyHWN4FbgBVUdCYwBVgNXAC+r6l7Ay+7zbtfaVcXgNA1F4gniCZvezxhT2HI2Q5mIlAMHA7MAVDUCRETkBGCau9qDwFzg8tb2lUgkUjP8tEdDQ0OLr31RsQ2AsiAZ9+3HqQ1UbaulpGjH6ww6W353yXcM+S6/J8Tg9fJ7QgxeL78tuawR7AFsAu4XkaUi8kcRKQV2UdX1AO79zpk2FpFzRGSxiCzevHlzlwdXWefUCPqVBjO+Hg44h8auLjbGFLpczlkcAMYBF6rqQhG5lXY0A6nqPcA9ABMmTNDOzPWZadttTh5gcP9yiovDO7zeq8Rd5i/q9DyjPWGe0nzHkO/ye0IMXi+/J8Tg9fJbkssawTpgnaoudJ8/gZMYNojIIAD3fmMOY2hRci6CviUtX1AGNl2lMabw5SwRqOqXwGcisre76HBgFfAMMNNdNhN4OlcxtKaippHycICiQOZDsH3eYjtzyBhT2HLZNARwIfCIiBQBHwNn4iSfx0XkB8Ba4OQcx5BRRYa5itOF3BpBvdUIjDEFLqeJQFWXARMyvHR4LsvNRkVNpMVTR8EZfRSg0RKBMabAefbK4spWriqGtKYhO2vIGFPgPJsIKmobW20a2t5ZbH0ExpjC5slEkEgoW+qirTcN2VlDxhiP8GQiqK6PEk9oxrmKk+ysIWOMV3gyEVS0MldxUrKz2GoExphC581EUJMccC6LPgLrLDbGFDhPJoKq+igAfUoyjzMEEApY05Axxhs8mQiq3UTQu7jlRODzCUUBn11HYIwpeN5MBHVt1wjAGYHU+giMMYXOk4mgqj6C3yeUhVq/sDoc9FvTkDGm4HkzEdRF6VMcRERaXS8c9FtnsTGm4HkzEdRH6d1GsxA41xJY05AxptB5MhFUuzWCtljTkDHGCzyZCKrqI62eMZQUDvitRmCMKXieTATV9VH6tDAzWbpQ0EdDzGoExpjC5slEUFUXza5GEPTbdQTGmILnuUQQiyfY1hBr8xoCSPYRWCIwxhQ2zyWCrQ0xgOw6iwM+6yw2xhQ8zyWCqjpnwLls+gjsOgJjjBdklQhEZE8RCbmPp4nIj0SkT25Dy42qLMYZSrLrCIwxXpBtjeBJIC4iXwPuA4YDf8lZVDmUGnAu6z6CBKqa67CMMSZvsk0ECVWNAScBt6jqJcCg3IWVO6kB57I8awig0U4hNcYUsGwTQVRETgVmAn93l7X9TdoDtaePIDknQaN1GBtjCli2ieBMYBJwvap+IiLDgYdzF1buJPsIysOtjzwKNkuZMcYb2v42BFR1FfAjABHpC/RS1d/mMrBcqaqL0iscIOBvOwemEoF1GBtjCli2Zw3NFZFyEekHvA3cLyI35za03Kiuz+6qYnDOGgKbrtIYU9iybRrqrapbgW8D96vqeOCI3IWVO844Q1kmgoDVCIwxhS/bRBAQkUHAd9neWfyVVFUXoU9x2x3FYE1DxhhvyDYR/BL4J/CRqi4SkT2AD3IXVu5kOykNpDUN2emjxpgClm1n8V+Bv6Y9/xj4f7kKKpeynZQGrEZgjPGGbDuLh4jIHBHZKCIbRORJERmS6+C6mqpS1Z4+glRnsSUCY0zhyrZp6H7gGWBXYDDwrLvsK6WmMUY8oVmfNRRyO4vtgjJjTCHLNhHspKr3q2rMvT0A7JTDuHIiOc5QuzuL7YIyY0wyhY5zAAAc5klEQVQByzYRbBaR00XE795OBypyGVguVNVlP+AcQHGR9REYYwpftongLJxTR78E1gPfwRl24itle40g2+sI7IIyY0zhyyoRqOpaVZ2uqjup6s6qeiLOxWVtcmsQS0Xk7+7z4SKyUEQ+EJHZIpJdO00XSNYIshlwDiDg9xHwidUIjDEFrTMzlF2a5XoXAavTnt8A/E5V9wK2AD/oRAztUlWfHHk0+4FTk3MSGGNMocrqOoIWSJsrOKeYHgtcD1wqIgIcBpzmrvIgcA1wV2v7SSQS1NfXtzvAhoaGJs83V9cBUEQs6/2FAkJtQ2OXlJ8P+Y4h3+X3hBi8Xn5PiMHr5belMzWCbKbtugX4KZD8Sd0fqHInuQFYh3M66g5E5BwRWSwiizdv3tyJMLerro8RCvhSZwNlIxTw25XFxpiC1mqNQES2kfkLX4DiNrY9DtioqktEZFrads1lTCiqeg9wD8CECRO0uLjV4lqV3LY2qvQpCdKefRUX+YklpF3btFR+PuU7hnyX3xNi8Hr5PSEGr5ffklYTgar26sS+pwDTReRbQBgox6kh9BGRgFsrGAJ80Yky2qWqPvsB55KcPgLrLDbGFK7ONA21SlWvVNUhqjoMOAV4RVW/B7yKc/opOFNfPp2rGJqrqst+wLmkcNBvF5QZYwpazhJBKy7H6Tj+EKfP4L7uKri6PvsB55LCQZ+dNWSMKWidOWsoa6o6F5jrPv4YmNgd5TZXVRdl/yHtTAQBf+r6A2OMKUT5qBHkTVV9JOsB55Ksj8AYU+g8kwgaonEaoomsrypOClnTkDGmwHkmEWx1xxnqSI2g0TqLjTEFzDOJoCo54Fx7zxoK2BATxpjC5p1EUNe+uQiSnLOGrEZgjClcHkoE7R9wDpymoVhCicWtVmCMKUzeSQQd7iNw5ySw8YaMMQXKM4kg1VncgRoB2CxlxpjC5ZlEUFUXxe8TeoXadw1dOGCJwBhT2LyTCNyLyZwpEbIXCtp0lcaYwuadRFDX/nGGwJqGjDGFzzOJoLq+/SOPwvZEYBeVGWMKlWcSQYdrBAFrGjLGFDbPJILq+mi7Tx0FaxoyxhQ+zySCqrpIuwecg/REYDUCY0xh8kQiiCeUrQ2xDtYIkk1DViMwxhQmTySCrR0ccA7SagTWWWyMKVCeSAQdHXkU0i8os6YhY0xh8kYiSA44186RRyH9gjKrERhjCpM3EoFbIyjvQB9BKOBDBBotERhjCpQnEkFn+ghEhFDAZ6OPGmMKlicSwfZJadqfCMAmsDfGFDZPJYKOnD4KyekqLREYYwqTNxJBfYReoQABf8ferjNdpTUNGWMKkycSQXVdxwacS7KmIWNMIfNEIqjq4DhDSaGg3zqLjTEFyxOJoLo+2qEzhpLCAR8NEasRGGMKkycSQVVdpEMXkyWFg34bYsIYU7A8kQg6OilNktNZbInAGFOYCj4RqGqHJ6VJcjqLrY/AGFOYCj4R1EXixBLayT4CO2vIGFO4Cj4RpEYe7VQfgTUNGWMKV8Engq0NMaBjA84lhe30UWNMASv4RFDdiQHnkkJBP5FYgkRCuyosY4zpMTyQCJwaQaf6CNw5CRqtVmCMKUA5SwQiMlREXhWR1SKyUkQucpf3E5F/icgH7n3fXMUAaTWCzvQRpGYps34CY0zhyWWNIAb8WFX3Ab4BXCAio4ArgJdVdS/gZfd5znRF05DNW2yMKWSBXO1YVdcD693H20RkNTAYOAGY5q72IDAXuLy1fSUSCerr69sdQ0NDAxXbGggFfGgsgttK1G4+dTas2lZHn3ZULBoaGjpWYBfKdwz5Lr8nxOD18ntCDF4vvy3d0kcgIsOAA4CFwC5ukkgmi51b2OYcEVksIos3b97c4bK3NsQoD3cu3yVrBNZHYIwpRDmrESSJSBnwJHCxqm4Vkay2U9V7gHsAJkyYoMXFxR0qvyaq9C0toqPbA5SXhp2YfIEO7aczZXeVfMeQ7/J7QgxeL78nxOD18luS0xqBiARxksAjqvo3d/EGERnkvj4I2JjLGKrro53qKIb0zmKrERhjCk8uzxoS4D5gtarenPbSM8BM9/FM4OlcxQDO6aOdGXAOnOsIwDqLjTGFKZdNQ1OA7wPviMgyd9nPgN8Cj4vID4C1wMk5jMGtEXQuERQn+wjs9FFjTAHK5VlDrwEtdQgcnqtym+vspDSw/YIyaxoyxhSigr6yOBJLUB9NdGqaSki7jsBqBMaYAlTQiaC6wbmYrHdJJzuLLREYYwpYYSeC5DhDna4RuE1Ddh2BMaYAFXgi6PzwEmBjDRljCps3EkEnryPw+YQiv886i40xBanAE0Hnh6BOCtksZcaYAlXgicCpEXRmdrKkcNBPo11QZowpQAWeCGL4BHqFOn+5hDNvsTUNGWMKT84Hncun6voo5eEgPp9ApBbWLYJPX3duVZ/CMb+Fkcdmta9wwG9NQ8aYglTQiWBg5Ztc7n8D7r0B1i+DRAzEBwP3g2ApPD4TTvkLjDiqzX2Fg5YIjDGFqaATwdTKv7F/bAn4vw6TfwS7T4GhEyFcDvVV8OcTYPbpcNpjsOdhre7LmoaMMYWqoBPBsNPv4Et/OUMHDdzxxeI+8P058ODx8OhpcPoTMGxqi/sKB/3UNHZwijNjjOnBCrqzuKT/UAb06d3KCv3gjKeh7+7wyHdh7ZstrhoK+K1GYIwpSAWdCLJSOgDOeAbKB8HD34F1SzKuFg76bBhqY0xBskQA0GsXJxmU9oeHT8qYDKyz2BhTqCwRJPUeDDOfhVA5/PFw54yiL99JvRwO+mzQOWNMQbJEkK7PbnDOPDjoUvjwZbh7Kjx6KqxbYtcRGGMKVkGfNdQhpf3h8Kth8oXwn3vhjTvhvcP4Xu8DWR07Am2cgoR65TtKY4zpMpYIWlLcFw75KXzjPFh0H7vMu5VHihbCb66H4n5O7SH99rUjoP+e+Y7aGGPazRJBW0K9YOrFzI4dyX9enM3vjupNuGYdVK2FTe/BB/+CWD0EiuH4W2HMjHxHbIwx7WKJIEuBcBnPJw7k2vGHE+4V3v6CqjNu0VMXwJxz4LOFcMxvIBDKX7DGGNMO1lmcpXDAOVSNzS8qE4G+w5wL0yb/CBbfB386Bqo+6/4gjTGmAywRZKnNCez9ATjqOvjuQ7D5A/jDwfg+mdt9ARpjTAdZIshSMhEs/KSSSGvXE4yaDufMhV4DKXr8VALzfg0fvgSfvwVb1kDDVqc5yRhjegjrI8jSXjuX0a+0iKueWsH/vvAux+w7kOPH7MqkPfoT8DfLpwO+Bme/RPzpHxF88zZ487amr/uCzllJA0bA7pNgt0nOqKh2WqoxJg8sEWRp2IBS3rzycBZ8uJln3/6C5975kscXr6N/aRHf2m8Q35+0OyN2SfsiLyoleuztxKb8hHCsGuoqob5y+33tZtiwAv59M2h8+zwJu02G3b4Bu0+Gsp3z94aNMZ5hiaAdigI+Dh25M4eO3JmGaJy5723i2eVf8NclnzF78Wdcd8JoZnx9t+0biKB9h0Fxccs7bdzmzJy29k1n5rQlD8DCu5zX+u3pJITdJzu1hr7DnM5pY4zpQpYIOigc9HPMvgM5Zt+BVNQ0ctFjy7j8yXdYvGYLvzxhX4qL/NntKNTLmRQnOTFOPApfLIO1r8Onb8DqZ2HpQwDUhXaiJtCPsqAS9iu+RBTiMUhEoagMxn0fxs9ymp2MMSZLBZ0IPt36KQFfgK8Vfy2n5fQvC/HgWRO59eUPuP2VD3jn82ruOn08A0s70BfvD8LQrzu3KRdBIkFi42qeefYJWPsmvagnhp+4+CkrLqZPr1L6l5eyS+wLAi9dA/P+F8Z+z7ki2q50NsZkoWATgapy3aLr+Hjrx/xqyq84fPfDc1qe3ydceuQIxu3Wh4tnL2P67a/xqxNGctQ+nWvnjyP8dH6MJz+awIWHncLZU/dgydpKln6yhUVrKlm+roroOqU46Oe+Yy5j8qbH4a0HYdEfYe9v4hv3AxJDJ3fRuzTGFCLRr8CpjBMmTNDFixe3e7sPN33Iz974Gau3rOb0fU7n0vGXEvQHcxBhU+u21HHBI2/x9rpqZn5jKBcdOZJ+pUXt3k8snuDSx9/mmbe/4NIjR/Cjw/faYZ36SJxln1Xx2xfeZfm6Kv7n2FGcNabESQSL/gj1lWggjPQeAr2HQO+hzq3PUOi3BwwaC8FwhtK7Rn19PQDFrfWT5Fi+Y/B6+T0hBq+WLyJLVHVCm+sVciKor68nEo9w16q7eGT1I+zbf19uPORGhvQakoMom2qMxbn26Xf4y6LPCfqFw0buzMnjhzJt7512PN00g0gswUWPLeX5FV9y+TEjOW9a68089ZE4F89eyj9XbmDW5GH8z3Gj8McbiCx7HNm4imDtl1D9GVSvg5oN2zf0h2DI150O6WFTYMhEKCrp7NvfHpd9CXm+/J4Qg1fLt0RA04P/0qcvcfWCqwG4bsp1OW8qSpb//sYann1nE3OWfk5FbYQBZSG+PW4w3xk/pOnppmkaY3EueOQtXlq9kauO3YezD9ojq/LiCeXXz63mvtc+4Yh9duG2U8ci8SjQ7B8w2gBbP4dN76JrFhD75DUCG99BNEFMAnwUGMFnOx/CbofMYsSIkZ0+BjuU383yHYPXy+8JMXi1fEsE7Hjw121bx2XzLmNFxQpOG3kaM0fPZNeyXbs01pbKj8YTvPruRv66ZB2vvruRWEIZUFbEzr3C7FweYhf3fufyMP9atYH572/iuhNG8/1Jw9pd7oOvr+HaZ1ey7+De3DFjX3YqC1FcXExjLM4HG2pY8Xk1K7/Yyur1W3l/wza2NsToRR3jfe9xSNH7TA2sYq/YBwCsCOzLthEnMfrwMyjvn7m/oz4S54vqegaWhykNNe12yvcHsCfE4PXye0IMXi3fEgGZD340HuXmJTfz8OqHARjeezhTdp3ClMFTmLDLBMKBrmsvb+mPv7mmkWff/oL3N2xj49ZGNmxrYOPWRjbXNJJQ51KB35y0H6dM3C3TbrPy0qoNXPjoUvqWBPnG8L68u6GWDzZuIxp3/t5loQD7DOrFiF2c2147l7HXLr0YUFaEiFC97j0+evUBdvrkGYYm1hFRP+/2+gaR3aexrT7C1ppaamtrqK+vIxppIESURooIl/WlX//+DNxpZ4buOpA+5eVIST/CO38NwuUdP5id4NUvgZ5Sfk+Iwavl9+hEICLHALcCfuCPqvrb1tbvykSQ9HH1x7y27jVe/+J1Fn25iEgiQsgfYvwu4xnZbySlwVJKAiXOfbCEkkAJZUVl9A/3Z0DxAEqCbbejb63ZSm2slv69+lPkb7uzOBZPUFkbAWDn8s4npHfWVfPDhxZTH42z7+De7Du4N6N3LWffXXuzW78SfL4sLk5T5cO3X2PT6w+x58YX2ZktTV5OIMR9RaivCF+8kYBGWtxVra8XlcFdqC4aSHVoEDXhQdT6+7DN14ut4t4opVpLKA6F2HunIkb197FXH2FgKIpE6yBSA4kEqHtDtz8Wn9PnESgCfwj1F1ET87GhJkplLMwWKaeiHiprG6mojVBRE0EEBpaH2aU8zMDe7q08zICyEPGEUh+NO7dInAb3sU+gNBSgLBSgVyhIacjfYr9PPKFsq60l6PdRWtJ1fS/tke8vwZ4Qg1fL77GJQET8wPvAkcA6YBFwqqquammbXCSCJuvF6lmyYQkLPl/Agi8WsG7bOqKJaKvblARKGFA8gAHFA+hf3B9BqI5UU924/VYXq0utX+QroqyojLJgGaXBUnoV9SLkDxH0BQn6gwR8AYI+594vfmKJGNFEdIf7oC9IabA0laBKA9sfh/1hQoEQYX+YcCBM2B9Go4pPfITD2xOL4vzNW/vb+3w+AhJIxRPwBYhFE1Ru/Jz+vUsJFIVI+ItIiJBASagzEJ/Eo2hDDV9s3MjHX2xk7RcbaKzeTN/YZvrGNzMgtomdE5sZmNhEGQ0IpG4+VZKpKUaAADEUUHESTjJaAfyq+CB1y1adhthKCdsoo95fRgMhamI+Iuonhp8ofqIaIEqAakrZomVUUcYW7ZV6XK8hfKIICSduEoQDQjgYoCERoD7hpyYRoCbup1GDgBAKCHv08fO13jC8PMHupXEGl8TpF0pQHQ+zKVbMhkiIzxtCfFkHFTURGmPOSLc+jRPWBoq1nrDWE5IYweJeBEv6ECrrQ3lpCX1KgvQuKSIU8OEXwecDnwh+nxCLusnZHyQSS9AYS7j3cSKxBEG/j7JQgNJQgNIiv3MfClBc5Mcnzn4keY9zH00kaIwmiMS330diCeIJpSggFPn9BANCkd9HUcBHIhZBkCb/h0kiEPA5sQZ8Pvde8PmEeEKJxp39R2MJonHneUM0zrbGGDUNMWrc+22NMeoaY5SFA/QrLaJfaRF9S5z7Yl+ccNCf+i5QVVQhoc6noTHm7DN5n3wMUBz0O7ciP+Ggn3DQR5Hf58amzrGMO8cyEkug7jFKP3aRxkZEoKS4OHUsk+uISOo9J4+DdNEIAj05EUwCrlHVo93nVwKo6m9a2mbcuHG6YMGCdpfV0NAAkPGfry3ReJS6WF2TW020hsqGSioaKpre6itQlN5FvSkvKqd3yLkv8Tk1iRgxaqI11ERrqI3VUhutpSZaQ2O8kVgitv3LXp37eCKeSgrJ+4AvQEACRBNRamO11EWdmNpKWJ6hgrhpJPlI3C8uZ6m6NycRKjQZBdaXtp5Ptz9O/3SkJyJJbqPgQ1PbK5BIlSao0GQfyY+3aPqy7dunPv4q7hNnxeQ+E2T+gkiVl7a5pr2WLDv53pLx+zJ8/KXZfXKdZML1pe80UyySFq+kH/mmZUiz561perxaKTsthmS5zctOvg9x99tSLMn75vvI9F7SH+8QX6ZjJU1f1maP0/9+1429ka+PmpZhJ20rKSnJKhHk44KywUD6rC3rgAObryQi5wDnAAwdOrR7IksT9Afp7e9N71DvDu+jM4koW9G4kxjqY/U0xhtpjDfSEG9IPd5Wvw1FCQaDqS9KIPWPKBk+VoqiqsQSMeIaT93HE3HiGscvfkQEn/i239yPl27/mgWFSDSCovgDflSVBAnnXhMkNJFaX9W5Ty5Dk1/kTjlA6j65bYJE6nFc46l9JO9TxygWRRACgYCTJNz9Jt97ernpcQiCJKIQa0BijfhijUi8EU3E3C86TfuCduLyqSIaRzSBL5FwBhSMRUF8SLAIfEWoP0gUP3VxPw0JKJIYRUQJEMEXj6LxRjTu/ILGH8DnKwJ/EJ+/CHxBxOeHRAziESQeQWMRErEIiVgjqCLa9MufhPNMfIL6mn7RqDi/jJO/jp330fTXsvP+0h87rXDJ/Ts/Xp1ft0pa4tDt/2OajCFDgkrdqzZ7nja0Vvq/rrtwh9qKgA9x/i4JZwcJt+UwkUiQPnh800S5vaD08nxuYk3+P6b+rd2nqZCSObvZRyk9KeEey9QvfW2+ZjIgRTT5g8Z5qW9Z7oeMyUciyJTQd8iZqnoPcA84TUOdaVvLZ9torssvpphyWu6E9WrbaE+Kwevl94QYvF5+W/IxMc06IP0n/hDgizzEYYwxhvwkgkXAXiIyXESKgFOAZ/IQhzHGGPLQNKSqMRH5b+CfOKeP/klVV3Z3HMYYYxx5GX1UVZ8DnstH2cYYY5qyyeuNMcbjLBEYY4zHWSIwxhiPs0RgjDEe95UYfVRENgGfdnDzAcDmLgznq1Z+T4gh3+X3hBi8Xn5PiMGL5e+uqju1tdJXIhF0hogszmasjUItvyfEkO/ye0IMXi+/J8Tg9fJbY01DxhjjcZYIjDHG47yQCO7xePmQ/xjyXT7kPwavlw/5j8Hr5beo4PsIjDHGtM4LNQJjjDGtsERgjDEeV9CJQESOEZH3RORDEbkiD+WvEZF3RGSZiLR/0uWOlfknEdkoIivSlvUTkX+JyAfufc6mPGqh/GtE5HP3OCwTkW/lsPyhIvKqiKwWkZUicpG7vFuOQSvld+cxCIvIf0TkbTeGa93lw0VkoXsMZrvDwHdn+Q+IyCdpx2BsLspPi8MvIktF5O/u8255/23E0K3HIGvOJM6Fd8MZ4vojYA+gCHgbGNXNMawBBnRzmQcD44AVacv+F7jCfXwFcEM3l38N8JNuev+DgHHu417A+8Co7joGrZTfncdAgDL3cRBYCHwDeBw4xV1+N3BeN5f/APCd7jgGbtmXAn8B/u4+75b330YM3XoMsr0Vco1gIvChqn6sqhHgMeCEPMeUc6o6H6hstvgE4EH38YPAid1cfrdR1fWq+pb7eBuwGmee7G45Bq2U323UUeM+Dbo3BQ4DnnCX5/IYtFR+txGRIcCxwB/d50I3vf+WYujJCjkRDAY+S3u+jm7+QOL8878oIktE5JxuLjvdLqq6HpwvKmDnPMTw3yKy3G06yv1s3ICIDAMOwPlF2u3HoFn50I3HwG2SWAZsBP6FUzuuUtWYu0pOPw/Ny1fV5DG43j0GvxORUK7KB24BfgqpOev7043vv4UYkrrrGGStkBOBZFjW3efKTlHVccA3gQtE5OBuLr+nuAvYExgLrAf+L9cFikgZ8CRwsapuzXV5WZTfrcdAVeOqOhZnTvCJwD6ZVuuu8kVkX+BKYCTwdaAfcHkuyhaR44CNqrokfXGmMHNRfisxQDcdg/Yq5ESwDhia9nwI8EV3BqCqX7j3G4E5OB/IfNggIoMA3PuN3Vm4qm5wvxgSwL3k+DiISBDnS/gRVf2bu7jbjkGm8rv7GCSpahUwF6eNvo+IJGcl7JbPQ1r5x7jNZqqqjcD95O4YTAGmi8ganCbhw3B+nXfn+98hBhF5uBuPQbsUciJYBOzlnilQBJwCPNNdhYtIqYj0Sj4GjgJWtL5VzjwDzHQfzwSe7s7Ck1/ArpPI4XFw24LvA1ar6s1pL3XLMWip/G4+BjuJSB/3cTFwBE5fxavAd9zVcnkMMpX/bloiFpz2+ZwcA1W9UlWHqOownM/9K6r6Pbrp/bcSw+nddQzaLd+91bm8Ad/COWvjI+Dn3Vz2HjhnKr0NrOyu8oFHcZoeoji1oh/gtI++DHzg3vfr5vIfAt4BluN8IQ/KYflTcar8y4Fl7u1b3XUMWim/O4/B/sBSt6wVwNVp/5P/AT4E/gqEurn8V9xjsAJ4GPfMolzegGlsP2OnW95/GzF0+zHI5mZDTBhjjMcVctOQMcaYLFgiMMYYj7NEYIwxHmeJwBhjPM4SgTHGeJwlAuMpIlLj3g8TkdO6eN8/a/b89a7cvzG5YonAeNUwoF2JQET8bazSJBGo6uR2xmRMXlgiMF71W+Agd0z4S9xB0m4UkUXugGA/BBCRae78An/BuRAIEXnKHUhwZXIwQRH5LVDs7u8Rd1my9iHuvleIMz/FjLR9zxWRJ0TkXRF5xL3i1JhuFWh7FWMK0hU48wMcB+B+oVer6tfdESEXiMiL7roTgX1V9RP3+VmqWukOn7BIRJ5U1StE5L/VGWituW/jDDY3BhjgbjPffe0AYDTOuDcLcMaoea3r364xLbMagTGOo4Az3KGTF+IMSbGX+9p/0pIAwI9E5G3gTZyBDfeidVOBR9UZdG4DMA9n9MnkvtepMxjdMpwmK2O6ldUIjHEIcKGq/rPJQpFpQG2z50cAk1S1TkTmAuEs9t2SxrTHcewzafLAagTGq7bhTCWZ9E/gPHcIaURkhDtqbHO9gS1uEhiJM7xzUjS5fTPzgRluP8ROONN5/qdL3oUxXcB+fRivWg7E3CaeB4BbcZpl3nI7bDeReSrDF4BzRWQ58B5O81DSPcByEXlLnWGPk+YAk3BGolXgp6r6pZtIjMk7G33UGGM8zpqGjDHG4ywRGGOMx1kiMMYYj7NEYIwxHmeJwBhjPM4SgTHGeJwlAmOM8bj/D4vO2JLcJhDHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss.plot.line()\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Loss of the Model Over Time')\n",
    "plt.xticks(np.arange(0, 50, step=5))\n",
    "plt.grid(True, linewidth=0.2);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
