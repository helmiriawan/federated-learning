{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.frecency import sample, frecency_points\n",
    "from data.frecency import sample_suggestions_normal as sample_suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from optimizers import GradientDescent, AdaptiveGradientDescent, DecayedGradientDescent, RProp, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointwise ranking\n",
    "\n",
    "The task in this study is pointwise ranking. Each item will be given a score by the model, which will be used for ranking all items. Since the score is a real number, the model that is used in this study is a regression function. Hinge loss, or also known as SVM loss, is used in the model optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_loss(preds, ys, delta=0):\n",
    "    correct = ys.argmax()\n",
    "    score_correct = preds[correct]\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for i, pred in enumerate(preds):\n",
    "        loss += max(0, pred + delta - score_correct)            \n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVMRanking:\n",
    "    def __init__(self, delta):\n",
    "        self.delta = delta\n",
    "        \n",
    "    def fit(self, data_generator, optimizer, num_iterations=10, constraints=[], callbacks=[]):\n",
    "        X, y = data_generator(2)\n",
    "        num_features = X[0].shape[1]\n",
    "        self.W = frecency_points + (np.random.random(size=(num_features)) - 0.5) * 100\n",
    "        self.loss = []\n",
    "        \n",
    "        for j in range(num_iterations):\n",
    "            X, y = data_generator(4000)\n",
    "            \n",
    "            preds = self.predict(X)\n",
    "            gradient = np.zeros(num_features)\n",
    "\n",
    "            for xi, pi, yi in zip(X, preds, y):\n",
    "                correct = yi.argmax()\n",
    "                score_correct = pi[correct]\n",
    "\n",
    "                for i, predicted_score in enumerate(pi):\n",
    "                    gradient -= xi[i] * max(0, predicted_score + self.delta - score_correct)\n",
    "            \n",
    "            gradient /= len(X)\n",
    "            \n",
    "            loss = np.mean([svm_loss(pi, yi) for pi, yi in zip(self.predict(X), y)])\n",
    "            accuracy = rank_accuracy(y, model.predict(X))\n",
    "            \n",
    "            print(\"[%d/%d] training: %.5f loss, %.3f accuracy\" % (j + 1, num_iterations, loss, accuracy))\n",
    "            \n",
    "            for callback in callbacks:\n",
    "                callback(self)\n",
    "            \n",
    "            self.W += optimizer(gradient)\n",
    "            self.loss.append(loss)\n",
    "            \n",
    "            for constraint in constraints:\n",
    "                self.W = constraint(self.W)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        \n",
    "        for x in X:\n",
    "            scores = x.dot(self.W)\n",
    "            preds.append(scores)\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two or more items can have the same score. However, there is only one correct answer. The correct answer should be the one that is used to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_accuracy(y, preds):\n",
    "    correct = 0.\n",
    "    \n",
    "    for yi, pi in zip(y, preds):\n",
    "        if yi[pi.argmax()] == yi.max():\n",
    "            correct += 1\n",
    "            \n",
    "    return correct / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case study, the model parameter should be non-negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FrecencyConstraints:\n",
    "    def __call__(self, gradient):\n",
    "        return gradient - min(0, gradient.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training in single server setting\n",
    "\n",
    "Training a machine learning model can be performed in a single machine with high computational resource. It can be done by store all the data in one single place and then use the data to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training: 3.80225 loss, 0.787 accuracy\n",
      "[ModelCheckpoint] New best model with 0.79670 validation accuracy\n",
      "[2/48] training: 1.60038 loss, 0.944 accuracy\n",
      "[ModelCheckpoint] New best model with 0.94620 validation accuracy\n",
      "[3/48] training: 0.77972 loss, 0.963 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96370 validation accuracy\n",
      "[4/48] training: 0.63540 loss, 0.964 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96460 validation accuracy\n",
      "[5/48] training: 0.35693 loss, 0.968 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[6/48] training: 0.56707 loss, 0.967 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[7/48] training: 0.39944 loss, 0.965 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96570 validation accuracy\n",
      "[8/48] training: 0.33584 loss, 0.961 accuracy\n",
      "[ModelCheckpoint] New best model with 0.96870 validation accuracy\n",
      "[9/48] training: 0.40017 loss, 0.963 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[10/48] training: 0.25135 loss, 0.967 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[11/48] training: 0.14411 loss, 0.970 accuracy\n",
      "validation: 0.962 accuracy\n",
      "[12/48] training: 0.14909 loss, 0.962 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[13/48] training: 0.15105 loss, 0.965 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[14/48] training: 0.10008 loss, 0.969 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[15/48] training: 0.12976 loss, 0.965 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[16/48] training: 0.11980 loss, 0.970 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[17/48] training: 0.09692 loss, 0.964 accuracy\n",
      "validation: 0.967 accuracy\n",
      "[18/48] training: 0.08039 loss, 0.966 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[19/48] training: 0.09652 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[20/48] training: 0.06384 loss, 0.965 accuracy\n",
      "validation: 0.968 accuracy\n",
      "[21/48] training: 0.05389 loss, 0.962 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[22/48] training: 0.06603 loss, 0.964 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[23/48] training: 0.04978 loss, 0.965 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[24/48] training: 0.05702 loss, 0.961 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[25/48] training: 0.03534 loss, 0.962 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[26/48] training: 0.05088 loss, 0.965 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[27/48] training: 0.04353 loss, 0.960 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[28/48] training: 0.02919 loss, 0.965 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[29/48] training: 0.04597 loss, 0.961 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[30/48] training: 0.04546 loss, 0.965 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[31/48] training: 0.05533 loss, 0.964 accuracy\n",
      "validation: 0.968 accuracy\n",
      "[32/48] training: 0.03115 loss, 0.962 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[33/48] training: 0.02815 loss, 0.962 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[34/48] training: 0.01073 loss, 0.969 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[35/48] training: 0.00830 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[36/48] training: 0.03234 loss, 0.966 accuracy\n",
      "validation: 0.962 accuracy\n",
      "[37/48] training: 0.02458 loss, 0.966 accuracy\n",
      "validation: 0.963 accuracy\n",
      "[38/48] training: 0.02474 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[39/48] training: 0.01768 loss, 0.967 accuracy\n",
      "validation: 0.965 accuracy\n",
      "[40/48] training: 0.01838 loss, 0.966 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[41/48] training: 0.03372 loss, 0.962 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[42/48] training: 0.01719 loss, 0.963 accuracy\n",
      "validation: 0.967 accuracy\n",
      "[43/48] training: 0.00932 loss, 0.964 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[44/48] training: 0.01877 loss, 0.963 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[45/48] training: 0.01093 loss, 0.965 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[46/48] training: 0.00770 loss, 0.963 accuracy\n",
      "validation: 0.964 accuracy\n",
      "[47/48] training: 0.01093 loss, 0.964 accuracy\n",
      "validation: 0.966 accuracy\n",
      "[48/48] training: 0.02531 loss, 0.963 accuracy\n",
      "validation: 0.967 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "model = SVMRanking(delta=0.)\n",
    "model.fit(data_generator=sample_suggestions,\n",
    "          optimizer=GradientDescent(30.),\n",
    "          num_iterations=48,\n",
    "          constraints=[FrecencyConstraints()],\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "serverGD = model.loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training, the learned model parameters can be compared with the true model parameters. Note that the model is evaluated by ranking the score of the items, not merely comparing the prediction and true score of the items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.0, 0.5433364435759508),\n",
       " (14.0, 8.960230542150786),\n",
       " (20.0, 0.0),\n",
       " (36.0, 44.143611676215514),\n",
       " (42.0, 44.26611215786202),\n",
       " (60.0, 44.251088298246984),\n",
       " (60.0, 44.14356711929147),\n",
       " (70.0, 95.40041275067807),\n",
       " (84.0, 95.40041275067648),\n",
       " (98.0, 106.93412445398285),\n",
       " (100.0, 106.93412442389078),\n",
       " (120.0, 124.57658116682717),\n",
       " (140.0, 161.82421533629864),\n",
       " (140.0, 161.82421533629864),\n",
       " (200.0, 272.4958278078269)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ais = np.argsort(frecency_points)\n",
    "zip(frecency_points[ais], model.W[ais])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training in federated learning setting\n",
    "\n",
    "In several situations, sometimes the server is not allowed to keep the data. To tackle this issue, training a machine learning model can be performed using federated learning setting. In this setting, the data still can be kept in the clients while the training process is performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self, clients):\n",
    "        self.clients = clients\n",
    "        \n",
    "        num_features = len(frecency_points)\n",
    "        self.W = np.int32(frecency_points + (np.random.random(size=(num_features)) - 0.5) * 100)\n",
    "    \n",
    "    def fit(self, optimizer, num_iterations, num_clients_per_iteration, constraints=[], callbacks=[]):\n",
    "        \n",
    "        self.loss = []\n",
    "        for j in range(num_iterations):\n",
    "            clients = random.sample(self.clients, num_clients_per_iteration)\n",
    "            updates, losses = zip(*[client.request_update(self) for client in clients])\n",
    "            \n",
    "            gradient = np.mean(updates, axis=0)\n",
    "            loss = np.mean(losses, axis=0)\n",
    "            \n",
    "            print(\"[%d/%d] training loss across clients %.5f\" % (j + 1, num_iterations, loss))\n",
    "            \n",
    "            for callback in callbacks:\n",
    "                callback(self)\n",
    "            \n",
    "            self.W += np.int32(optimizer(gradient))\n",
    "            self.loss.append(loss)\n",
    "            \n",
    "            for constraint in constraints:\n",
    "                self.W = constraint(self.W)\n",
    "            \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        \n",
    "        for x in X:\n",
    "            scores = x.dot(self.W)\n",
    "            preds.append(scores)\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnalyticalClient:\n",
    "    def __init__(self, data_generator, delta=0):\n",
    "        self.data_generator = data_generator\n",
    "        self.delta = 0\n",
    "    \n",
    "    def request_update(self, model):\n",
    "        X, y = self.data_generator()\n",
    "        preds = model.predict(X)\n",
    "        \n",
    "        num_features = X[0].shape[1]\n",
    "        gradient = np.zeros(num_features)\n",
    "        loss = 0\n",
    "\n",
    "        for xi, pi, yi in zip(X, preds, y):\n",
    "            correct = yi.argmax()\n",
    "            score_correct = pi[correct]\n",
    "\n",
    "            for i, predicted_score in enumerate(pi):\n",
    "                gradient -= xi[i] * max(0, predicted_score + self.delta - score_correct)\n",
    "            \n",
    "            loss += svm_loss(pi, yi)\n",
    "                \n",
    "        gradient /= len(X)\n",
    "        loss /= len(X)\n",
    "        \n",
    "        return gradient, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this experiment, 5000 clients are used to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients = [AnalyticalClient(lambda: sample_suggestions(np.int32(np.random.exponential(.8)) + 2)) for _ in range(5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training loss across clients 12.50804\n",
      "[ModelCheckpoint] New best model with 0.75240 validation accuracy\n",
      "[2/48] training loss across clients 54.66287\n",
      "validation: 0.591 accuracy\n",
      "[3/48] training loss across clients 89.68266\n",
      "[ModelCheckpoint] New best model with 0.82900 validation accuracy\n",
      "[4/48] training loss across clients 6.24904\n",
      "[ModelCheckpoint] New best model with 0.97820 validation accuracy\n",
      "[5/48] training loss across clients 5.24104\n",
      "validation: 0.975 accuracy\n",
      "[6/48] training loss across clients 2.98337\n",
      "[ModelCheckpoint] New best model with 0.97940 validation accuracy\n",
      "[7/48] training loss across clients 1.87258\n",
      "validation: 0.979 accuracy\n",
      "[8/48] training loss across clients 1.57953\n",
      "[ModelCheckpoint] New best model with 0.98100 validation accuracy\n",
      "[9/48] training loss across clients 4.44021\n",
      "validation: 0.979 accuracy\n",
      "[10/48] training loss across clients 3.73792\n",
      "validation: 0.979 accuracy\n",
      "[11/48] training loss across clients 1.19375\n",
      "[ModelCheckpoint] New best model with 0.98160 validation accuracy\n",
      "[12/48] training loss across clients 1.76146\n",
      "validation: 0.980 accuracy\n",
      "[13/48] training loss across clients 2.25171\n",
      "[ModelCheckpoint] New best model with 0.98540 validation accuracy\n",
      "[14/48] training loss across clients 1.12688\n",
      "validation: 0.977 accuracy\n",
      "[15/48] training loss across clients 1.52021\n",
      "validation: 0.982 accuracy\n",
      "[16/48] training loss across clients 0.87562\n",
      "validation: 0.981 accuracy\n",
      "[17/48] training loss across clients 0.77708\n",
      "validation: 0.980 accuracy\n",
      "[18/48] training loss across clients 0.84333\n",
      "validation: 0.980 accuracy\n",
      "[19/48] training loss across clients 0.33417\n",
      "validation: 0.976 accuracy\n",
      "[20/48] training loss across clients 0.35042\n",
      "validation: 0.980 accuracy\n",
      "[21/48] training loss across clients 0.59517\n",
      "validation: 0.979 accuracy\n",
      "[22/48] training loss across clients 0.84062\n",
      "validation: 0.981 accuracy\n",
      "[23/48] training loss across clients 0.52883\n",
      "validation: 0.980 accuracy\n",
      "[24/48] training loss across clients 0.64308\n",
      "validation: 0.981 accuracy\n",
      "[25/48] training loss across clients 0.48588\n",
      "validation: 0.981 accuracy\n",
      "[26/48] training loss across clients 0.54479\n",
      "validation: 0.982 accuracy\n",
      "[27/48] training loss across clients 0.16538\n",
      "validation: 0.981 accuracy\n",
      "[28/48] training loss across clients 0.42625\n",
      "validation: 0.981 accuracy\n",
      "[29/48] training loss across clients 0.42633\n",
      "validation: 0.983 accuracy\n",
      "[30/48] training loss across clients 0.21946\n",
      "validation: 0.985 accuracy\n",
      "[31/48] training loss across clients 0.18667\n",
      "validation: 0.981 accuracy\n",
      "[32/48] training loss across clients 0.27292\n",
      "validation: 0.981 accuracy\n",
      "[33/48] training loss across clients 0.12708\n",
      "validation: 0.981 accuracy\n",
      "[34/48] training loss across clients 0.10725\n",
      "validation: 0.981 accuracy\n",
      "[35/48] training loss across clients 0.19175\n",
      "validation: 0.981 accuracy\n",
      "[36/48] training loss across clients 0.11417\n",
      "validation: 0.975 accuracy\n",
      "[37/48] training loss across clients 0.11563\n",
      "validation: 0.981 accuracy\n",
      "[38/48] training loss across clients 0.06958\n",
      "validation: 0.982 accuracy\n",
      "[39/48] training loss across clients 0.13962\n",
      "validation: 0.982 accuracy\n",
      "[40/48] training loss across clients 0.29988\n",
      "validation: 0.982 accuracy\n",
      "[41/48] training loss across clients 0.06875\n",
      "validation: 0.981 accuracy\n",
      "[42/48] training loss across clients 0.08221\n",
      "validation: 0.977 accuracy\n",
      "[43/48] training loss across clients 0.18083\n",
      "validation: 0.981 accuracy\n",
      "[44/48] training loss across clients 0.06883\n",
      "validation: 0.982 accuracy\n",
      "[45/48] training loss across clients 0.14589\n",
      "validation: 0.982 accuracy\n",
      "[46/48] training loss across clients 0.12354\n",
      "validation: 0.980 accuracy\n",
      "[47/48] training loss across clients 0.10246\n",
      "validation: 0.978 accuracy\n",
      "[48/48] training loss across clients 0.04938\n",
      "validation: 0.980 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "server = Server(clients)\n",
    "server.fit(optimizer=GradientDescent(30.),\n",
    "          num_iterations=48,\n",
    "           num_clients_per_iteration=400,\n",
    "           constraints=[FrecencyConstraints()],\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions, 5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "federatedGD = server.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.0, 0),\n",
       " (14.0, 151),\n",
       " (20.0, 149),\n",
       " (36.0, 144),\n",
       " (42.0, 564),\n",
       " (60.0, 561),\n",
       " (60.0, 567),\n",
       " (70.0, 775),\n",
       " (84.0, 826),\n",
       " (98.0, 856),\n",
       " (100.0, 855),\n",
       " (120.0, 967),\n",
       " (140.0, 1018),\n",
       " (140.0, 1018),\n",
       " (200.0, 1123)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(frecency_points[ais], server.W[ais])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training in federated learning setting using RProp\n",
    "\n",
    "RProp, or resilient backpropagation, is a learning method that ignores the magnitude of the gradient and only uses the sign of the gradient. The main motivation of RProp is to avoid experimenting different learning rates to train the model. In addition, it can also be used to reduce the size of the data that is sent from clients to the server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training loss across clients 12.50804\n",
      "[ModelCheckpoint] New best model with 0.75240 validation accuracy\n",
      "[2/48] training loss across clients 13.21671\n",
      "[ModelCheckpoint] New best model with 0.75560 validation accuracy\n",
      "[3/48] training loss across clients 10.19690\n",
      "[ModelCheckpoint] New best model with 0.75900 validation accuracy\n",
      "[4/48] training loss across clients 8.77127\n",
      "[ModelCheckpoint] New best model with 0.79860 validation accuracy\n",
      "[5/48] training loss across clients 8.40608\n",
      "validation: 0.797 accuracy\n",
      "[6/48] training loss across clients 6.13325\n",
      "[ModelCheckpoint] New best model with 0.80240 validation accuracy\n",
      "[7/48] training loss across clients 5.91335\n",
      "validation: 0.799 accuracy\n",
      "[8/48] training loss across clients 5.21768\n",
      "[ModelCheckpoint] New best model with 0.86460 validation accuracy\n",
      "[9/48] training loss across clients 4.51546\n",
      "[ModelCheckpoint] New best model with 0.87060 validation accuracy\n",
      "[10/48] training loss across clients 4.57298\n",
      "validation: 0.869 accuracy\n",
      "[11/48] training loss across clients 3.27062\n",
      "validation: 0.868 accuracy\n",
      "[12/48] training loss across clients 2.92000\n",
      "[ModelCheckpoint] New best model with 0.87180 validation accuracy\n",
      "[13/48] training loss across clients 2.19942\n",
      "[ModelCheckpoint] New best model with 0.87400 validation accuracy\n",
      "[14/48] training loss across clients 1.15423\n",
      "[ModelCheckpoint] New best model with 0.90580 validation accuracy\n",
      "[15/48] training loss across clients 1.24329\n",
      "[ModelCheckpoint] New best model with 0.91460 validation accuracy\n",
      "[16/48] training loss across clients 1.07704\n",
      "[ModelCheckpoint] New best model with 0.93380 validation accuracy\n",
      "[17/48] training loss across clients 0.71725\n",
      "validation: 0.934 accuracy\n",
      "[18/48] training loss across clients 0.50917\n",
      "[ModelCheckpoint] New best model with 0.95640 validation accuracy\n",
      "[19/48] training loss across clients 0.65358\n",
      "validation: 0.955 accuracy\n",
      "[20/48] training loss across clients 0.67250\n",
      "validation: 0.953 accuracy\n",
      "[21/48] training loss across clients 0.59387\n",
      "validation: 0.951 accuracy\n",
      "[22/48] training loss across clients 0.40542\n",
      "validation: 0.951 accuracy\n",
      "[23/48] training loss across clients 0.34467\n",
      "[ModelCheckpoint] New best model with 0.95820 validation accuracy\n",
      "[24/48] training loss across clients 0.12733\n",
      "validation: 0.958 accuracy\n",
      "[25/48] training loss across clients 0.14521\n",
      "[ModelCheckpoint] New best model with 0.96160 validation accuracy\n",
      "[26/48] training loss across clients 0.05458\n",
      "validation: 0.959 accuracy\n",
      "[27/48] training loss across clients 0.20719\n",
      "validation: 0.869 accuracy\n",
      "[28/48] training loss across clients 0.01875\n",
      "[ModelCheckpoint] New best model with 1.00000 validation accuracy\n",
      "[29/48] training loss across clients 0.16475\n",
      "validation: 0.924 accuracy\n",
      "[30/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[31/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[32/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[33/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[34/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[35/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[36/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[37/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[38/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[39/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[40/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[41/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[42/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[43/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[44/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[45/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[46/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[47/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n",
      "[48/48] training loss across clients 0.00000\n",
      "validation: 1.000 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "opt = opt = RProp(2., len(frecency_points), min_value=1, max_value=3, alpha=2., beta=0.6)\n",
    "server = Server(clients)\n",
    "server.fit(optimizer=opt,\n",
    "          num_iterations=48,\n",
    "           num_clients_per_iteration=400,\n",
    "           constraints=[FrecencyConstraints()],\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions, 5000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "federatedRProp = server.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.0, 0),\n",
       " (14.0, 22),\n",
       " (20.0, 24),\n",
       " (36.0, 26),\n",
       " (42.0, 37),\n",
       " (60.0, 98),\n",
       " (60.0, 98),\n",
       " (70.0, 104),\n",
       " (84.0, 105),\n",
       " (98.0, 107),\n",
       " (100.0, 109),\n",
       " (120.0, 140),\n",
       " (140.0, 142),\n",
       " (140.0, 142),\n",
       " (200.0, 203)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(frecency_points[ais], server.W[ais])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For comparison, we also try RProp in single server setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/48] training: 3.80225 loss, 0.787 accuracy\n",
      "[ModelCheckpoint] New best model with 0.79670 validation accuracy\n",
      "[2/48] training: 3.50662 loss, 0.802 accuracy\n",
      "[ModelCheckpoint] New best model with 0.80270 validation accuracy\n",
      "[3/48] training: 2.56823 loss, 0.892 accuracy\n",
      "[ModelCheckpoint] New best model with 0.89950 validation accuracy\n",
      "[4/48] training: 2.05177 loss, 0.918 accuracy\n",
      "[ModelCheckpoint] New best model with 0.91950 validation accuracy\n",
      "[5/48] training: 1.37913 loss, 0.919 accuracy\n",
      "validation: 0.914 accuracy\n",
      "[6/48] training: 1.35307 loss, 0.912 accuracy\n",
      "validation: 0.918 accuracy\n",
      "[7/48] training: 0.98318 loss, 0.976 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97690 validation accuracy\n",
      "[8/48] training: 1.08884 loss, 0.973 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97770 validation accuracy\n",
      "[9/48] training: 0.96941 loss, 0.978 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[10/48] training: 0.82543 loss, 0.978 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[11/48] training: 0.73172 loss, 0.975 accuracy\n",
      "validation: 0.973 accuracy\n",
      "[12/48] training: 0.67947 loss, 0.977 accuracy\n",
      "validation: 0.975 accuracy\n",
      "[13/48] training: 0.68620 loss, 0.974 accuracy\n",
      "validation: 0.977 accuracy\n",
      "[14/48] training: 0.47279 loss, 0.981 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[15/48] training: 0.48518 loss, 0.976 accuracy\n",
      "validation: 0.975 accuracy\n",
      "[16/48] training: 0.46020 loss, 0.976 accuracy\n",
      "validation: 0.975 accuracy\n",
      "[17/48] training: 0.35200 loss, 0.976 accuracy\n",
      "[ModelCheckpoint] New best model with 0.97900 validation accuracy\n",
      "[18/48] training: 0.27137 loss, 0.982 accuracy\n",
      "validation: 0.976 accuracy\n",
      "[19/48] training: 0.21224 loss, 0.977 accuracy\n",
      "validation: 0.978 accuracy\n",
      "[20/48] training: 0.21128 loss, 0.979 accuracy\n",
      "validation: 0.979 accuracy\n",
      "[21/48] training: 0.09107 loss, 0.980 accuracy\n",
      "validation: 0.977 accuracy\n",
      "[22/48] training: 0.09837 loss, 0.992 accuracy\n",
      "[ModelCheckpoint] New best model with 0.99280 validation accuracy\n",
      "[23/48] training: 0.01064 loss, 0.999 accuracy\n",
      "[ModelCheckpoint] New best model with 0.99680 validation accuracy\n",
      "[24/48] training: 0.07126 loss, 0.999 accuracy\n",
      "[ModelCheckpoint] New best model with 0.99880 validation accuracy\n",
      "[25/48] training: 0.01361 loss, 1.000 accuracy\n",
      "validation: 0.999 accuracy\n",
      "[26/48] training: 0.08487 loss, 0.999 accuracy\n",
      "validation: 0.999 accuracy\n",
      "[27/48] training: 0.01606 loss, 0.997 accuracy\n",
      "validation: 0.998 accuracy\n",
      "[28/48] training: 0.08526 loss, 0.999 accuracy\n",
      "validation: 0.998 accuracy\n",
      "[29/48] training: 0.01095 loss, 0.998 accuracy\n",
      "validation: 0.998 accuracy\n",
      "[30/48] training: 0.07651 loss, 0.999 accuracy\n",
      "[ModelCheckpoint] New best model with 0.99910 validation accuracy\n",
      "[31/48] training: 0.01217 loss, 0.999 accuracy\n",
      "validation: 0.998 accuracy\n",
      "[32/48] training: 0.20546 loss, 0.911 accuracy\n",
      "validation: 0.917 accuracy\n",
      "[33/48] training: 0.03280 loss, 0.937 accuracy\n",
      "validation: 0.938 accuracy\n",
      "[34/48] training: 0.43807 loss, 0.875 accuracy\n",
      "validation: 0.877 accuracy\n",
      "[35/48] training: 0.04831 loss, 0.923 accuracy\n",
      "validation: 0.921 accuracy\n",
      "[36/48] training: 0.63000 loss, 0.768 accuracy\n",
      "validation: 0.756 accuracy\n",
      "[37/48] training: 0.08611 loss, 0.846 accuracy\n",
      "validation: 0.837 accuracy\n",
      "[38/48] training: 0.41507 loss, 0.768 accuracy\n",
      "validation: 0.774 accuracy\n",
      "[39/48] training: 0.04952 loss, 0.904 accuracy\n",
      "validation: 0.901 accuracy\n",
      "[40/48] training: 0.35916 loss, 0.850 accuracy\n",
      "validation: 0.848 accuracy\n",
      "[41/48] training: 0.05264 loss, 0.901 accuracy\n",
      "validation: 0.902 accuracy\n",
      "[42/48] training: 0.43277 loss, 0.829 accuracy\n",
      "validation: 0.838 accuracy\n",
      "[43/48] training: 0.04898 loss, 0.888 accuracy\n",
      "validation: 0.886 accuracy\n",
      "[44/48] training: 0.39695 loss, 0.840 accuracy\n",
      "validation: 0.839 accuracy\n",
      "[45/48] training: 0.05035 loss, 0.901 accuracy\n",
      "validation: 0.897 accuracy\n",
      "[46/48] training: 0.42075 loss, 0.833 accuracy\n",
      "validation: 0.830 accuracy\n",
      "[47/48] training: 0.05602 loss, 0.896 accuracy\n",
      "validation: 0.904 accuracy\n",
      "[48/48] training: 0.37848 loss, 0.838 accuracy\n",
      "validation: 0.854 accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "opt = opt = RProp(2., len(frecency_points), min_value=1, max_value=3, alpha=2., beta=0.6)\n",
    "model = SVMRanking(delta=0.)\n",
    "model.fit(data_generator=sample_suggestions,\n",
    "          optimizer=opt,\n",
    "          num_iterations=48,\n",
    "          constraints=[FrecencyConstraints()],\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "serverRProp = model.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(12.0, 0.8841395490909747),\n",
       " (14.0, 1.964414843229335),\n",
       " (20.0, 0.0),\n",
       " (36.0, 2.5443888997861563),\n",
       " (42.0, 2.3030498667128256),\n",
       " (60.0, 3.0718100137430895),\n",
       " (60.0, 3.1435671192914683),\n",
       " (70.0, 108.81441964384018),\n",
       " (84.0, 111.79769150093125),\n",
       " (98.0, 111.73605317801935),\n",
       " (100.0, 113.88456966395219),\n",
       " (120.0, 114.57658116682717),\n",
       " (140.0, 114.3305922286066),\n",
       " (140.0, 114.82421533629864),\n",
       " (200.0, 287.4958278078268)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(frecency_points[ais], model.W[ais])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance comparison\n",
    "\n",
    "Learning in different settings can affect the convergence rate of the training process. The higher the convergence rate, the fewer number of iterations are needed to achieve the target. In this study, we are interested in comparing the convergence rate of different settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.DataFrame({\n",
    "    'Server_GD': serverGD,\n",
    "    'Server_RProp': serverRProp,\n",
    "    'Federated_GD': federatedGD,\n",
    "    'Federated_RProp': federatedRProp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss.plot.line()\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.title('Loss of the Model Over Time')\n",
    "plt.xticks(np.arange(0, 50, step=5))\n",
    "plt.grid(True, linewidth=0.2);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
