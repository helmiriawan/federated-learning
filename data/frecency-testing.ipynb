{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Federated Learning\n",
    "\n",
    "This notebook is the simulation notebook adapted so that intermediate data is saved.\n",
    "This data can be used to unit test the Scala port of the server-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:15:35.357273Z",
     "start_time": "2018-07-06T23:15:35.324901Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:15:36.736247Z",
     "start_time": "2018-07-06T23:15:36.324006Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:15:38.005754Z",
     "start_time": "2018-07-06T23:15:37.989345Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:15:38.802737Z",
     "start_time": "2018-07-06T23:15:38.728721Z"
    }
   },
   "outputs": [],
   "source": [
    "from data.frecency import sample, frecency_points\n",
    "from data.frecency import sample_suggestions_normal as sample_suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:15:39.330381Z",
     "start_time": "2018-07-06T23:15:39.249988Z"
    }
   },
   "outputs": [],
   "source": [
    "from optimizers import GradientDescent, AdaptiveGradientDescent, DecayedGradientDescent, RProp, Adam\n",
    "from utils import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:15:40.012334Z",
     "start_time": "2018-07-06T23:15:39.993994Z"
    }
   },
   "outputs": [],
   "source": [
    "def svm_loss(preds, ys, delta=0):\n",
    "    correct = ys.argmax()\n",
    "    score_correct = preds[correct]\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for i, pred in enumerate(preds):\n",
    "        loss += max(0, pred + delta - score_correct)            \n",
    "            \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:15:40.339941Z",
     "start_time": "2018-07-06T23:15:40.315057Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_url_features(num_samples):\n",
    "    frequencies = np.int32(np.random.exponential(7, size=num_samples)) + 1\n",
    "    frequencies = np.int32(np.ones(num_samples))\n",
    "    X = []\n",
    "    \n",
    "    for frequency in frequencies:\n",
    "        num_sampled = min(10, frequency)\n",
    "        features = sample_weighted(num_sampled, weights).sum(axis=0)\n",
    "        X.append(frequency / num_sampled * features)\n",
    "        \n",
    "    return np.array(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:15:40.561579Z",
     "start_time": "2018-07-06T23:15:40.539727Z"
    }
   },
   "outputs": [],
   "source": [
    "def rank_accuracy(y, preds):\n",
    "    correct = 0.\n",
    "    \n",
    "    for yi, pi in zip(y, preds):\n",
    "        if yi[pi.argmax()] == yi.max():\n",
    "            correct += 1\n",
    "            \n",
    "    return correct / len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Federated Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:15:41.339886Z",
     "start_time": "2018-07-06T23:15:41.321430Z"
    }
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:15:41.806337Z",
     "start_time": "2018-07-06T23:15:41.760519Z"
    }
   },
   "outputs": [],
   "source": [
    "class Server:\n",
    "    def __init__(self, clients):\n",
    "        self.clients = clients\n",
    "        \n",
    "        num_features = len(frecency_points)\n",
    "        self.W = np.int32(frecency_points + (np.random.random(size=(num_features)) - 0.5) * 300)\n",
    "        self.W = np.maximum(1, self.W)\n",
    "    \n",
    "    def fit(self, optimizer, num_iterations, num_clients_per_iteration, constraints=[], callbacks=[]):        \n",
    "        update_list = []\n",
    "        W_list = [self.W.copy()]\n",
    "        \n",
    "        for j in range(num_iterations):\n",
    "            clients = random.sample(self.clients, num_clients_per_iteration)\n",
    "            updates, losses = zip(*[client.request_update(self) for client in clients])\n",
    "            update_list.append(updates)\n",
    "            \n",
    "            gradient = np.mean(updates, axis=0)\n",
    "            loss = np.mean(losses, axis=0)\n",
    "            \n",
    "            print(\"[%d/%d] training loss across clients %.5f\" % (j + 1, num_iterations, loss))\n",
    "            \n",
    "            for callback in callbacks:\n",
    "                callback(self)\n",
    "            \n",
    "            self.W += np.int32(optimizer(gradient))\n",
    "            \n",
    "            for constraint in constraints:\n",
    "                self.W = constraint(self.W)\n",
    "                \n",
    "            W_list.append(self.W.copy())\n",
    "                \n",
    "        return update_list, W_list\n",
    "            \n",
    "    def predict(self, X):\n",
    "        preds = []\n",
    "        \n",
    "        for x in X:\n",
    "            scores = x.dot(self.W)\n",
    "            preds.append(scores)\n",
    "        \n",
    "        return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:15:42.313162Z",
     "start_time": "2018-07-06T23:15:42.290259Z"
    }
   },
   "outputs": [],
   "source": [
    "class FrecencyConstraints:\n",
    "    def __call__(self, gradient):\n",
    "        return gradient - min(0, gradient.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical gradient computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:15:43.000469Z",
     "start_time": "2018-07-06T23:15:42.983313Z"
    }
   },
   "outputs": [],
   "source": [
    "def full_loss(model, loss_fn, X, y):\n",
    "    preds = model.predict(X)\n",
    "    return sum([loss_fn(pi, yi) for pi, yi in zip(preds, y)]) / len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:15:43.347188Z",
     "start_time": "2018-07-06T23:15:43.319949Z"
    }
   },
   "outputs": [],
   "source": [
    "class NumericalClient:\n",
    "    def __init__(self, data_generator, delta=0):\n",
    "        self.data_generator = data_generator\n",
    "        self.delta = 0\n",
    "    \n",
    "    def request_update(self, model, eps=1):\n",
    "        X, y = self.data_generator()\n",
    "        loss = full_loss(model, svm_loss, X, y)\n",
    "        \n",
    "        num_features = X[0].shape[1]\n",
    "        gradient = []\n",
    "        \n",
    "        for i in range(num_features):\n",
    "            model.W[i] -= eps\n",
    "            loss1 = full_loss(model, svm_loss, X, y)\n",
    "            \n",
    "            model.W[i] += 2 * eps\n",
    "            loss2 = full_loss(model, svm_loss, X, y)\n",
    "            \n",
    "            finite_difference = (loss1 - loss2) / (2 * eps)\n",
    "            gradient.append(finite_difference)\n",
    "            \n",
    "            model.W[i] -= eps\n",
    "        \n",
    "        return gradient, loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:15:44.014985Z",
     "start_time": "2018-07-06T23:15:43.990749Z"
    }
   },
   "outputs": [],
   "source": [
    "clients = [NumericalClient(lambda: sample_suggestions(np.int32(np.random.exponential(.8)) + 2)) for _ in range(5000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:16:11.211523Z",
     "start_time": "2018-07-06T23:15:44.434705Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/30] training loss across clients 148.37488\n",
      "[ModelCheckpoint] New best model with 0.56180 validation accuracy\n",
      "[2/30] training loss across clients 147.48179\n",
      "validation: 0.551 accuracy\n",
      "[3/30] training loss across clients 135.38525\n",
      "validation: 0.561 accuracy\n",
      "[4/30] training loss across clients 113.15793\n",
      "[ModelCheckpoint] New best model with 0.57460 validation accuracy\n",
      "[5/30] training loss across clients 113.14079\n",
      "validation: 0.570 accuracy\n",
      "[6/30] training loss across clients 94.57138\n",
      "validation: 0.571 accuracy\n",
      "[7/30] training loss across clients 95.50639\n",
      "[ModelCheckpoint] New best model with 0.58480 validation accuracy\n",
      "[8/30] training loss across clients 87.81560\n",
      "validation: 0.577 accuracy\n",
      "[9/30] training loss across clients 82.10962\n",
      "[ModelCheckpoint] New best model with 0.58980 validation accuracy\n",
      "[10/30] training loss across clients 75.38465\n",
      "validation: 0.586 accuracy\n",
      "[11/30] training loss across clients 64.29371\n",
      "[ModelCheckpoint] New best model with 0.59180 validation accuracy\n",
      "[12/30] training loss across clients 57.04496\n",
      "validation: 0.588 accuracy\n",
      "[13/30] training loss across clients 51.84723\n",
      "[ModelCheckpoint] New best model with 0.60140 validation accuracy\n",
      "[14/30] training loss across clients 41.50413\n",
      "[ModelCheckpoint] New best model with 0.60260 validation accuracy\n",
      "[15/30] training loss across clients 40.39321\n",
      "[ModelCheckpoint] New best model with 0.65160 validation accuracy\n",
      "[16/30] training loss across clients 36.65175\n",
      "validation: 0.646 accuracy\n",
      "[17/30] training loss across clients 28.98454\n",
      "validation: 0.650 accuracy\n",
      "[18/30] training loss across clients 21.98092\n",
      "[ModelCheckpoint] New best model with 0.66220 validation accuracy\n",
      "[19/30] training loss across clients 22.47375\n",
      "[ModelCheckpoint] New best model with 0.76760 validation accuracy\n",
      "[20/30] training loss across clients 21.56796\n",
      "[ModelCheckpoint] New best model with 0.76800 validation accuracy\n",
      "[21/30] training loss across clients 17.50958\n",
      "validation: 0.766 accuracy\n",
      "[22/30] training loss across clients 12.77111\n",
      "[ModelCheckpoint] New best model with 0.78380 validation accuracy\n",
      "[23/30] training loss across clients 11.98982\n",
      "[ModelCheckpoint] New best model with 0.80800 validation accuracy\n",
      "[24/30] training loss across clients 8.16896\n",
      "validation: 0.799 accuracy\n",
      "[25/30] training loss across clients 7.09796\n",
      "[ModelCheckpoint] New best model with 0.82520 validation accuracy\n",
      "[26/30] training loss across clients 5.56846\n",
      "[ModelCheckpoint] New best model with 0.82920 validation accuracy\n",
      "[27/30] training loss across clients 3.84805\n",
      "[ModelCheckpoint] New best model with 0.90620 validation accuracy\n",
      "[28/30] training loss across clients 2.51317\n",
      "[ModelCheckpoint] New best model with 0.91760 validation accuracy\n",
      "[29/30] training loss across clients 2.03467\n",
      "[ModelCheckpoint] New best model with 0.92320 validation accuracy\n",
      "[30/30] training loss across clients 1.52343\n",
      "[ModelCheckpoint] New best model with 0.93320 validation accuracy\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(10)\n",
    "opt = opt = RProp(2., len(frecency_points), min_value=1, max_value=3, alpha=2., beta=0.6)\n",
    "server = Server(clients)\n",
    "updates, Ws = server.fit(optimizer=opt,\n",
    "          num_iterations=30,\n",
    "           num_clients_per_iteration=400,\n",
    "           constraints=[FrecencyConstraints()],\n",
    "          callbacks=[ModelCheckpoint(rank_accuracy, sample_suggestions, 5000)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:16:12.746112Z",
     "start_time": "2018-07-06T23:16:11.214560Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(len(updates)):\n",
    "    np.savetxt(\"updates-%.2d.csv\" % i, updates[i], fmt=\"%.7f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-06T23:16:12.807503Z",
     "start_time": "2018-07-06T23:16:12.748669Z"
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"weights.csv\", np.int32(Ws), fmt=\"%d\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "1162px",
    "left": "0px",
    "right": "1494px",
    "top": "160px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
